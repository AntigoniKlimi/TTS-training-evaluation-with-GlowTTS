{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4dbe5b77",
      "metadata": {
        "id": "4dbe5b77"
      },
      "source": [
        "# Glow-TTS Training 01"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0baea02",
      "metadata": {},
      "source": [
        "## Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bE8z5rXqesH_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE8z5rXqesH_",
        "outputId": "c4ef1556-29c0-4581-f433-59d485e7f245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount google drive for data storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56af6ad4",
      "metadata": {
        "id": "56af6ad4"
      },
      "source": [
        "## Install Coqui TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fa2aec78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-06-17T20:31:04.573216Z",
          "iopub.status.busy": "2024-06-17T20:31:04.572353Z",
          "iopub.status.idle": "2024-06-17T20:31:51.176383Z",
          "shell.execute_reply": "2024-06-17T20:31:51.175162Z",
          "shell.execute_reply.started": "2024-06-17T20:31:04.573184Z"
        },
        "id": "fa2aec78",
        "outputId": "0c38dd46-a641-4e35-a749-a9a6013b4d44",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n",
            "Collecting TTS\n",
            "  Downloading TTS-0.22.0-cp310-cp310-manylinux1_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.0.10)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.11.4)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.3.0+cu121)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.2.post1)\n",
            "Collecting scikit-learn>=1.3.0 (from TTS)\n",
            "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (7.0.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (4.66.4)\n",
            "Collecting anyascii>=0.3.0 (from TTS)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0.1)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.9.5)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (24.1)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n",
            "Collecting pysbd>=0.3.4 (from TTS)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting umap-learn>=0.5.1 (from TTS)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pandas<2.0,>=1.4 (from TTS)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n",
            "Collecting trainer>=0.0.32 (from TTS)\n",
            "  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting coqpit>=0.0.16 (from TTS)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
            "Collecting pypinyin (from TTS)\n",
            "  Downloading pypinyin-0.51.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hangul-romanize (from TTS)\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from TTS)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting bangla (from TTS)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting bnnumerizer (from TTS)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer (from TTS)\n",
            "  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting einops>=0.6.0 (from TTS)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (4.41.2)\n",
            "Collecting encodec>=0.1.1 (from TTS)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.3.2 (from TTS)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting num2words (from TTS)\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.7.5)\n",
            "Collecting numpy==1.22.0 (from TTS)\n",
            "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.58.1)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.15.0)\n",
            "Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (4.0.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (8.1.7)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (2.7.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (4.12.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa>=0.10.0 (from TTS)\n",
            "  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0.post2-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0.post1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (2.8.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->TTS)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->TTS) (0.41.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS) (2023.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->TTS) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.0->TTS) (1.16.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.4.0)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS)\n",
            "  Downloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS)\n",
            "  Downloading SudachiDict_core-20240409-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (1.12.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1->TTS)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1->TTS)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (2.15.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.23.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.4.3)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.22)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=2.0.1->TTS) (2.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0->TTS) (4.2.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=5.6.0->TTS) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=5.6.0->TTS) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (7.0.4)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1->TTS) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS) (1.3.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS) (3.2.2)\n",
            "Downloading TTS-0.22.0-cp310-cp310-manylinux1_x86_64.whl (938 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trainer-0.0.36-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n",
            "Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading pypinyin-0.51.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiDict_core-20240409-py3-none-any.whl (72.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gruut, encodec, bnnumerizer, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75791 sha256=d3b6b01ae213279d2ed9db1baf1ffaaaeef50debe9c9c893742e6a443ea8f1ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45762 sha256=830f2cb3a0351f8738b3c5dadd52a2a4f14b97bd193cdbfd83ea216ec32ef76b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5261 sha256=dec8ba84f53ca40e962cf409ee3fb4a77c2e617182e5c83ea8b324f809e0b76f\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=c5e48f810c77b52a4c00d74f0342351eb5324a85e294d00bb85a78dff04a73af\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104870 sha256=179f252ef0c3679918adc3c29ec6025536398a3d40c38fdcba5803504c6e6643\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498183 sha256=483fa5e1a87b725b36ed1e79c5faa2d3ba0e3011ba3476daab02277c3e4d75ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297178 sha256=367f83918e3400b89b81a55e2cfd59e49e8d4836c2439d068283c8a1345cd64f\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173797 sha256=f0655cb2af64f847e28b4d819c0c21624363a5b6be78bcedf52518fa513937e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968767 sha256=eec9e38561125d230b2541c88affe0408f1a11dc8261a6f5a8214cc1cf888b48\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
            "Successfully built gruut encodec bnnumerizer docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\n",
            "Installing collected packages: sudachipy, python-crfsuite, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, sudachidict-core, pysbd, pypinyin, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, num2words, networkx, jsonlines, gruut-ipa, einops, coqpit, anyascii, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, g2pkk, dateparser, scikit-learn, nvidia-cusolver-cu12, gruut, pynndescent, librosa, umap-learn, trainer, encodec, TTS\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.2.post1\n",
            "    Uninstalling librosa-0.10.2.post1:\n",
            "      Successfully uninstalled librosa-0.10.2.post1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "pywavelets 1.6.0 requires numpy<3,>=1.22.4, but you have numpy 1.22.0 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TTS-0.22.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 coqpit-0.0.17 dateparser-1.1.8 docopt-0.6.2 einops-0.8.0 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 jamo-0.4.1 jsonlines-1.2.0 librosa-0.10.0 networkx-2.8.8 num2words-0.5.13 numpy-1.22.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pandas-1.5.3 pynndescent-0.5.13 pypinyin-0.51.0 pysbd-0.3.4 python-crfsuite-0.9.10 scikit-learn-1.5.0 sudachidict-core-20240409 sudachipy-0.6.8 trainer-0.0.36 umap-learn-0.5.6 unidecode-1.3.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "739b903ff2634a33ae09c0b3928c1474",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.0.0 (from tensorflow)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, optree, numpy, tensorboard, ml-dtypes, h5py, keras, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.0\n",
            "    Uninstalling numpy-1.22.0:\n",
            "      Successfully uninstalled numpy-1.22.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 1.26.4 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 numpy-1.26.4 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# upgrade pip, install tts, and upgrade tensorflow\n",
        "! pip install -U pip\n",
        "! pip install TTS\n",
        "! pip install -U tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c8eaa71",
      "metadata": {
        "id": "0c8eaa71"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "97b30b4d",
      "metadata": {
        "id": "97b30b4d"
      },
      "outputs": [],
      "source": [
        "# import the necessary libraries\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from trainer import Trainer, TrainerArgs\n",
        "\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "from TTS.tts.models.glow_tts import GlowTTS\n",
        "from TTS.tts.datasets import load_tts_samples\n",
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "357c4e0e",
      "metadata": {
        "id": "357c4e0e"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-17T20:31:51.179342Z",
          "iopub.status.busy": "2024-06-17T20:31:51.178913Z",
          "iopub.status.idle": "2024-06-17T20:31:53.177657Z",
          "shell.execute_reply": "2024-06-17T20:31:53.176795Z",
          "shell.execute_reply.started": "2024-06-17T20:31:51.179290Z"
        },
        "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# set output path under google drive directory\n",
        "output_path = \"/content/drive/MyDrive/ljspeech-002/tts_train_dir\"\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "# set the dataset configuration\n",
        "# ljspeech dataset was chosen, but only one speaker (002) will be used\n",
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\", meta_file_train=\"/content/drive/MyDrive/ljspeech-002/metadata.csv\", path=\"/content/drive/MyDrive/ljspeech-002\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ab70e8",
      "metadata": {
        "id": "96ab70e8"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-17T20:31:53.187133Z",
          "iopub.status.busy": "2024-06-17T20:31:53.186857Z",
          "iopub.status.idle": "2024-06-17T20:31:53.217943Z",
          "shell.execute_reply": "2024-06-17T20:31:53.216972Z",
          "shell.execute_reply.started": "2024-06-17T20:31:53.187109Z"
        },
        "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# model architecture and configuration\n",
        "# 250 epochs will be trained with 32 training batch size\n",
        "# checkpoints every 200 steps, meaning around every 19 epochs,\n",
        "# since 337 training samples / 32 batch size = 10.5 steps per epoch\n",
        "config = GlowTTSConfig(\n",
        "    batch_size=32,\n",
        "    eval_batch_size=16,\n",
        "    num_loader_workers=4,\n",
        "    num_eval_loader_workers=4,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    epochs=250,\n",
        "    text_cleaner=\"phoneme_cleaners\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    print_step=25,\n",
        "    print_eval=False,\n",
        "    mixed_precision=True,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    save_step=200,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93ed377-80b7-447b-bd92-106bffa777ee",
      "metadata": {
        "id": "b93ed377-80b7-447b-bd92-106bffa777ee"
      },
      "source": [
        "## Audio Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b1b12f61-f851-4565-84dd-7640947e04ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-17T20:31:53.219259Z",
          "iopub.status.busy": "2024-06-17T20:31:53.218985Z",
          "iopub.status.idle": "2024-06-17T20:31:55.395938Z",
          "shell.execute_reply": "2024-06-17T20:31:55.394968Z",
          "shell.execute_reply.started": "2024-06-17T20:31:53.219235Z"
        },
        "id": "b1b12f61-f851-4565-84dd-7640947e04ab",
        "outputId": "08e0b7ea-fcad-480a-a783-241aad43b653",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:45\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ],
      "source": [
        "# audio processor for feature extraction and audio input/output\n",
        "ap = AudioProcessor.init_from_config(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d461683-b05e-403f-815f-8007bda08c38",
      "metadata": {
        "id": "1d461683-b05e-403f-815f-8007bda08c38"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "014879b7-f18d-44c0-b24a-e10f8002113a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-17T20:31:55.397546Z",
          "iopub.status.busy": "2024-06-17T20:31:55.397054Z",
          "iopub.status.idle": "2024-06-17T20:32:00.227234Z",
          "shell.execute_reply": "2024-06-17T20:32:00.226398Z",
          "shell.execute_reply.started": "2024-06-17T20:31:55.397516Z"
        },
        "id": "014879b7-f18d-44c0-b24a-e10f8002113a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# tokenizer for converting text to sequences of token ids\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978",
      "metadata": {
        "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978"
      },
      "source": [
        "## Load Data Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-17T20:32:00.229151Z",
          "iopub.status.busy": "2024-06-17T20:32:00.228530Z",
          "iopub.status.idle": "2024-06-17T20:32:00.568750Z",
          "shell.execute_reply": "2024-06-17T20:32:00.567768Z",
          "shell.execute_reply.started": "2024-06-17T20:32:00.229114Z"
        },
        "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7",
        "outputId": "d0f646b8-8573-4e97-f835-b183d811587f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Found 337 files in /content/drive/MyDrive/ljspeech-002\n"
          ]
        }
      ],
      "source": [
        "# load the training and evaluation samples from the dataset\n",
        "# each sample is a list of [text, audio_file_path, speaker_name]\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    eval_split_size=config.eval_split_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19",
      "metadata": {
        "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19"
      },
      "source": [
        "## Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-17T20:32:01.295471Z",
          "iopub.status.busy": "2024-06-17T20:32:01.294832Z",
          "iopub.status.idle": "2024-06-17T20:32:05.789353Z",
          "shell.execute_reply": "2024-06-17T20:32:05.788343Z",
          "shell.execute_reply.started": "2024-06-17T20:32:01.295415Z"
        },
        "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe",
        "outputId": "6946e41b-ffab-4934-baec-06ceb6eb0879",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " > Training Environment:\n",
            " | > Backend: Torch\n",
            " | > Mixed precision: True\n",
            " | > Precision: fp16\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " | > Torch TF32 MatMul: False\n",
            " > Start Tensorboard: tensorboard --logdir=/content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            " > Model has 28610257 parameters\n"
          ]
        }
      ],
      "source": [
        "# model initialization with configuration, audio processor, tokenizer, and no speaker manager\n",
        "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)\n",
        "\n",
        "# trainer generic api for training the model\n",
        "trainer = Trainer(\n",
        "    TrainerArgs(),\n",
        "    config,\n",
        "    output_path,\n",
        "    model=model,\n",
        "    train_samples=train_samples,\n",
        "    eval_samples=eval_samples\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b320831-dd83-429b-bb6a-473f9d49d321",
      "metadata": {
        "id": "5b320831-dd83-429b-bb6a-473f9d49d321"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-06-17T20:32:05.792249Z",
          "iopub.status.busy": "2024-06-17T20:32:05.791931Z",
          "iopub.status.idle": "2024-06-17T21:12:43.142735Z",
          "shell.execute_reply": "2024-06-17T21:12:43.141536Z",
          "shell.execute_reply.started": "2024-06-17T20:32:05.792223Z"
        },
        "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f",
        "outputId": "49a03060-9946-4647-a8ff-e98d24c4a785",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:47:59) \u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 334\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 179\n",
            " | > Min text length: 32\n",
            " | > Avg text length: 107.95808383233533\n",
            " | \n",
            " | > Max audio length: 222643.0\n",
            " | > Min audio length: 33971.0\n",
            " | > Avg audio length: 146823.3113772455\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 17:48:06 -- STEP: 0/11 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 1.6499  (1.6499032974243164)\n",
            "     | > loader_time: 4.9393  (4.939289569854736)\n",
            "\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 3\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 148\n",
            " | > Min text length: 85\n",
            " | > Avg text length: 125.66666666666667\n",
            " | \n",
            " | > Max audio length: 208051.0\n",
            " | > Min audio length: 103603.0\n",
            " | > Avg audio length: 168029.66666666666\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5940234661102295 \u001b[0m(+0)\n",
            "     | > avg_loss: 3.2766103744506836 \u001b[0m(+0)\n",
            "     | > avg_log_mle: 0.7733529210090637 \u001b[0m(+0)\n",
            "     | > avg_loss_dur: 2.5032575130462646 \u001b[0m(+0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_11.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:48:25) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5805544853210449 \u001b[0m(-0.01346898078918457)\n",
            "     | > avg_loss:\u001b[92m 3.276465892791748 \u001b[0m(-0.00014448165893554688)\n",
            "     | > avg_log_mle:\u001b[92m 0.7733439207077026 \u001b[0m(-9.000301361083984e-06)\n",
            "     | > avg_loss_dur:\u001b[92m 2.503121852874756 \u001b[0m(-0.00013566017150878906)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_22.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:48:53) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 17:49:10 -- STEP: 3/11 -- GLOBAL_STEP: 25\u001b[0m\n",
            "     | > loss: 3.323932409286499  (3.2615102926890054)\n",
            "     | > log_mle: 0.7773687243461609  (0.774429976940155)\n",
            "     | > loss_dur: 2.5465636253356934  (2.4870803356170654)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.2588, device='cuda:0')  (tensor(9.1272, device='cuda:0'))\n",
            "     | > current_lr: 5e-07 \n",
            "     | > step_time: 1.2682  (2.996190071105957)\n",
            "     | > loader_time: 0.0458  (0.041476170221964516)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5656437873840332 \u001b[0m(-0.014910697937011719)\n",
            "     | > avg_loss:\u001b[91m 3.2785868644714355 \u001b[0m(+0.0021209716796875)\n",
            "     | > avg_log_mle:\u001b[92m 0.7732728719711304 \u001b[0m(-7.104873657226562e-05)\n",
            "     | > avg_loss_dur:\u001b[91m 2.5053141117095947 \u001b[0m(+0.002192258834838867)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 3/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:49:25) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.605745792388916 \u001b[0m(+0.04010200500488281)\n",
            "     | > avg_loss:\u001b[92m 3.2760980129241943 \u001b[0m(-0.002488851547241211)\n",
            "     | > avg_log_mle:\u001b[92m 0.7731207013130188 \u001b[0m(-0.00015217065811157227)\n",
            "     | > avg_loss_dur:\u001b[92m 2.5029773712158203 \u001b[0m(-0.002336740493774414)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_44.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 4/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:49:54) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 17:50:14 -- STEP: 6/11 -- GLOBAL_STEP: 50\u001b[0m\n",
            "     | > loss: 3.3791732788085938  (3.2910900513331094)\n",
            "     | > log_mle: 0.7706016302108765  (0.7736319800217947)\n",
            "     | > loss_dur: 2.608571767807007  (2.517458160718282)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.3402, device='cuda:0')  (tensor(9.1603, device='cuda:0'))\n",
            "     | > current_lr: 1e-06 \n",
            "     | > step_time: 0.8794  (1.793956200281779)\n",
            "     | > loader_time: 0.0205  (0.02990269660949707)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5962274074554443 \u001b[0m(-0.00951838493347168)\n",
            "     | > avg_loss:\u001b[92m 3.2666733264923096 \u001b[0m(-0.009424686431884766)\n",
            "     | > avg_log_mle:\u001b[92m 0.7728716731071472 \u001b[0m(-0.00024902820587158203)\n",
            "     | > avg_loss_dur:\u001b[92m 2.4938015937805176 \u001b[0m(-0.009175777435302734)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_55.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 5/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:50:30) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5621511936187744 \u001b[0m(-0.03407621383666992)\n",
            "     | > avg_loss:\u001b[92m 3.2659976482391357 \u001b[0m(-0.0006756782531738281)\n",
            "     | > avg_log_mle:\u001b[92m 0.7725121974945068 \u001b[0m(-0.00035947561264038086)\n",
            "     | > avg_loss_dur:\u001b[92m 2.493485450744629 \u001b[0m(-0.0003161430358886719)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_66.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 6/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:51:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 17:51:27 -- STEP: 9/11 -- GLOBAL_STEP: 75\u001b[0m\n",
            "     | > loss: 3.3649682998657227  (3.3222584989335804)\n",
            "     | > log_mle: 0.7750558853149414  (0.7724690172407362)\n",
            "     | > loss_dur: 2.5899124145507812  (2.549789481692844)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.2436, device='cuda:0')  (tensor(9.1847, device='cuda:0'))\n",
            "     | > current_lr: 1.5e-06 \n",
            "     | > step_time: 0.8121  (1.8302273485395644)\n",
            "     | > loader_time: 0.0072  (0.05917835235595703)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.459458827972412 \u001b[0m(+0.8973076343536377)\n",
            "     | > avg_loss:\u001b[92m 3.264819383621216 \u001b[0m(-0.0011782646179199219)\n",
            "     | > avg_log_mle:\u001b[92m 0.772026538848877 \u001b[0m(-0.0004856586456298828)\n",
            "     | > avg_loss_dur:\u001b[92m 2.492792844772339 \u001b[0m(-0.0006926059722900391)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_77.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 7/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:51:43) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6157042980194092 \u001b[0m(-0.8437545299530029)\n",
            "     | > avg_loss:\u001b[92m 3.236936569213867 \u001b[0m(-0.027882814407348633)\n",
            "     | > avg_log_mle:\u001b[92m 0.7714007496833801 \u001b[0m(-0.0006257891654968262)\n",
            "     | > avg_loss_dur:\u001b[92m 2.465535879135132 \u001b[0m(-0.02725696563720703)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_88.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 8/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:52:17) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6018407344818115 \u001b[0m(-0.013863563537597656)\n",
            "     | > avg_loss:\u001b[92m 3.2280774116516113 \u001b[0m(-0.00885915756225586)\n",
            "     | > avg_log_mle:\u001b[92m 0.77061927318573 \u001b[0m(-0.0007814764976501465)\n",
            "     | > avg_loss_dur:\u001b[92m 2.457458257675171 \u001b[0m(-0.008077621459960938)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_99.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 9/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:52:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 17:52:57 -- STEP: 1/11 -- GLOBAL_STEP: 100\u001b[0m\n",
            "     | > loss: 3.204267740249634  (3.204267740249634)\n",
            "     | > log_mle: 0.7703370451927185  (0.7703370451927185)\n",
            "     | > loss_dur: 2.4339306354522705  (2.4339306354522705)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(8.8596, device='cuda:0')  (tensor(8.8596, device='cuda:0'))\n",
            "     | > current_lr: 2.25e-06 \n",
            "     | > step_time: 1.4456  (1.445643663406372)\n",
            "     | > loader_time: 0.0059  (0.005932807922363281)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.4447875022888184 \u001b[0m(+0.8429467678070068)\n",
            "     | > avg_loss:\u001b[92m 3.2173547744750977 \u001b[0m(-0.010722637176513672)\n",
            "     | > avg_log_mle:\u001b[92m 0.7696624994277954 \u001b[0m(-0.0009567737579345703)\n",
            "     | > avg_loss_dur:\u001b[92m 2.447692394256592 \u001b[0m(-0.009765863418579102)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_110.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 10/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:53:24) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6544675827026367 \u001b[0m(-0.7903199195861816)\n",
            "     | > avg_loss:\u001b[92m 3.2074856758117676 \u001b[0m(-0.009869098663330078)\n",
            "     | > avg_log_mle:\u001b[92m 0.7685023546218872 \u001b[0m(-0.0011601448059082031)\n",
            "     | > avg_loss_dur:\u001b[92m 2.438983201980591 \u001b[0m(-0.008709192276000977)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_121.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 11/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:53:56) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 17:54:14 -- STEP: 4/11 -- GLOBAL_STEP: 125\u001b[0m\n",
            "     | > loss: 3.2824621200561523  (3.2219132781028748)\n",
            "     | > log_mle: 0.7662936449050903  (0.7684989422559738)\n",
            "     | > loss_dur: 2.5161685943603516  (2.4534143805503845)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(8.8824, device='cuda:0')  (tensor(8.7739, device='cuda:0'))\n",
            "     | > current_lr: 2.75e-06 \n",
            "     | > step_time: 1.1281  (2.4822961688041687)\n",
            "     | > loader_time: 0.0066  (0.052026450634002686)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5867002010345459 \u001b[0m(-0.06776738166809082)\n",
            "     | > avg_loss:\u001b[92m 3.191110134124756 \u001b[0m(-0.01637554168701172)\n",
            "     | > avg_log_mle:\u001b[92m 0.7671111822128296 \u001b[0m(-0.0013911724090576172)\n",
            "     | > avg_loss_dur:\u001b[92m 2.423999071121216 \u001b[0m(-0.014984130859375)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_132.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 12/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:54:32) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5838136672973633 \u001b[0m(-0.002886533737182617)\n",
            "     | > avg_loss:\u001b[92m 3.181905746459961 \u001b[0m(-0.009204387664794922)\n",
            "     | > avg_log_mle:\u001b[92m 0.7654535174369812 \u001b[0m(-0.0016576647758483887)\n",
            "     | > avg_loss_dur:\u001b[92m 2.416452169418335 \u001b[0m(-0.007546901702880859)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_143.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 13/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:55:07) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 17:55:29 -- STEP: 7/11 -- GLOBAL_STEP: 150\u001b[0m\n",
            "     | > loss: 3.3698692321777344  (3.2580715247562955)\n",
            "     | > log_mle: 0.7598863840103149  (0.7647691283907209)\n",
            "     | > loss_dur: 2.609982967376709  (2.493302413395473)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(8.9073, device='cuda:0')  (tensor(8.6747, device='cuda:0'))\n",
            "     | > current_lr: 3.25e-06 \n",
            "     | > step_time: 0.8328  (2.2303572722843716)\n",
            "     | > loader_time: 0.0095  (0.027141128267560686)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6133379936218262 \u001b[0m(+0.02952432632446289)\n",
            "     | > avg_loss:\u001b[91m 3.2007336616516113 \u001b[0m(+0.01882791519165039)\n",
            "     | > avg_log_mle:\u001b[92m 0.763481616973877 \u001b[0m(-0.001971900463104248)\n",
            "     | > avg_loss_dur:\u001b[91m 2.4372520446777344 \u001b[0m(+0.020799875259399414)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 14/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:55:39) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6105659008026123 \u001b[0m(-0.002772092819213867)\n",
            "     | > avg_loss:\u001b[92m 3.1897339820861816 \u001b[0m(-0.010999679565429688)\n",
            "     | > avg_log_mle:\u001b[92m 0.7611300945281982 \u001b[0m(-0.002351522445678711)\n",
            "     | > avg_loss_dur:\u001b[92m 2.4286038875579834 \u001b[0m(-0.008648157119750977)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 15/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:56:01) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 17:56:21 -- STEP: 10/11 -- GLOBAL_STEP: 175\u001b[0m\n",
            "     | > loss: 3.3595895767211914  (3.2580215454101564)\n",
            "     | > log_mle: 0.7600702047348022  (0.7605641543865204)\n",
            "     | > loss_dur: 2.5995194911956787  (2.4974573850631714)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(8.5408, device='cuda:0')  (tensor(8.4103, device='cuda:0'))\n",
            "     | > current_lr: 3.7499999999999997e-06 \n",
            "     | > step_time: 0.435  (1.5169767379760741)\n",
            "     | > loader_time: 0.0048  (0.018746709823608397)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5850090980529785 \u001b[0m(-0.02555680274963379)\n",
            "     | > avg_loss:\u001b[92m 3.1603784561157227 \u001b[0m(-0.029355525970458984)\n",
            "     | > avg_log_mle:\u001b[92m 0.7583253383636475 \u001b[0m(-0.0028047561645507812)\n",
            "     | > avg_loss_dur:\u001b[92m 2.402053117752075 \u001b[0m(-0.026550769805908203)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_176.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 16/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:56:37) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.5952401161193848 \u001b[0m(+0.01023101806640625)\n",
            "     | > avg_loss:\u001b[92m 3.127124071121216 \u001b[0m(-0.033254384994506836)\n",
            "     | > avg_log_mle:\u001b[92m 0.7549845576286316 \u001b[0m(-0.003340780735015869)\n",
            "     | > avg_loss_dur:\u001b[92m 2.3721394538879395 \u001b[0m(-0.029913663864135742)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_187.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 17/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:57:10) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6124792098999023 \u001b[0m(+0.017239093780517578)\n",
            "     | > avg_loss:\u001b[92m 3.0913853645324707 \u001b[0m(-0.03573870658874512)\n",
            "     | > avg_log_mle:\u001b[92m 0.7509661912918091 \u001b[0m(-0.00401836633682251)\n",
            "     | > avg_loss_dur:\u001b[92m 2.340419054031372 \u001b[0m(-0.03172039985656738)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_198.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 18/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:57:46) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 17:57:58 -- STEP: 2/11 -- GLOBAL_STEP: 200\u001b[0m\n",
            "     | > loss: 3.129201889038086  (3.101369619369507)\n",
            "     | > log_mle: 0.7493588328361511  (0.750066488981247)\n",
            "     | > loss_dur: 2.37984299659729  (2.3513031005859375)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(7.5819, device='cuda:0')  (tensor(7.5388, device='cuda:0'))\n",
            "     | > current_lr: 4.5e-06 \n",
            "     | > step_time: 3.9198  (3.133118510246277)\n",
            "     | > loader_time: 0.1036  (0.05705440044403076)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_200.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6462440490722656 \u001b[0m(+0.03376483917236328)\n",
            "     | > avg_loss:\u001b[91m 3.137986421585083 \u001b[0m(+0.046601057052612305)\n",
            "     | > avg_log_mle:\u001b[92m 0.7461228370666504 \u001b[0m(-0.004843354225158691)\n",
            "     | > avg_loss_dur:\u001b[91m 2.3918635845184326 \u001b[0m(+0.05144453048706055)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 19/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:58:21) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7416417598724365 \u001b[0m(+0.0953977108001709)\n",
            "     | > avg_loss:\u001b[92m 3.0917108058929443 \u001b[0m(-0.04627561569213867)\n",
            "     | > avg_log_mle:\u001b[92m 0.7403454780578613 \u001b[0m(-0.0057773590087890625)\n",
            "     | > avg_loss_dur:\u001b[92m 2.351365327835083 \u001b[0m(-0.04049825668334961)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 20/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:58:47) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 17:59:03 -- STEP: 5/11 -- GLOBAL_STEP: 225\u001b[0m\n",
            "     | > loss: 3.094041109085083  (3.077825403213501)\n",
            "     | > log_mle: 0.7410126328468323  (0.7395579218864441)\n",
            "     | > loss_dur: 2.3530285358428955  (2.338267517089844)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(6.5144, device='cuda:0')  (tensor(6.6301, device='cuda:0'))\n",
            "     | > current_lr: 4.9999999999999996e-06 \n",
            "     | > step_time: 0.7642  (1.9702104568481444)\n",
            "     | > loader_time: 0.0194  (0.04199914932250977)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6099941730499268 \u001b[0m(-0.13164758682250977)\n",
            "     | > avg_loss:\u001b[92m 3.073735237121582 \u001b[0m(-0.017975568771362305)\n",
            "     | > avg_log_mle:\u001b[92m 0.7335646152496338 \u001b[0m(-0.006780862808227539)\n",
            "     | > avg_loss_dur:\u001b[92m 2.3401706218719482 \u001b[0m(-0.011194705963134766)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_231.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 21/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:59:20) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6037907600402832 \u001b[0m(-0.006203413009643555)\n",
            "     | > avg_loss:\u001b[92m 3.0621960163116455 \u001b[0m(-0.011539220809936523)\n",
            "     | > avg_log_mle:\u001b[92m 0.7258253693580627 \u001b[0m(-0.007739245891571045)\n",
            "     | > avg_loss_dur:\u001b[92m 2.3363707065582275 \u001b[0m(-0.003799915313720703)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_242.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 22/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 17:59:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:00:20 -- STEP: 8/11 -- GLOBAL_STEP: 250\u001b[0m\n",
            "     | > loss: 3.1764607429504395  (3.0777639150619507)\n",
            "     | > log_mle: 0.7165369987487793  (0.7203900590538979)\n",
            "     | > loss_dur: 2.45992374420166  (2.357373833656311)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.8879, device='cuda:0')  (tensor(5.8584, device='cuda:0'))\n",
            "     | > current_lr: 5.5e-06 \n",
            "     | > step_time: 0.7269  (2.039338618516922)\n",
            "     | > loader_time: 0.0074  (0.03074514865875244)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6128394603729248 \u001b[0m(+0.009048700332641602)\n",
            "     | > avg_loss:\u001b[92m 3.052027702331543 \u001b[0m(-0.010168313980102539)\n",
            "     | > avg_log_mle:\u001b[92m 0.7172236442565918 \u001b[0m(-0.008601725101470947)\n",
            "     | > avg_loss_dur:\u001b[92m 2.334804058074951 \u001b[0m(-0.0015666484832763672)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_253.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 23/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:00:36) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6142604351043701 \u001b[0m(+0.0014209747314453125)\n",
            "     | > avg_loss:\u001b[92m 2.9910922050476074 \u001b[0m(-0.06093549728393555)\n",
            "     | > avg_log_mle:\u001b[92m 0.7079848647117615 \u001b[0m(-0.009238779544830322)\n",
            "     | > avg_loss_dur:\u001b[92m 2.283107280731201 \u001b[0m(-0.05169677734375)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_264.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 24/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:01:13) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.592235803604126 \u001b[0m(-0.02202463150024414)\n",
            "     | > avg_loss:\u001b[92m 2.9534027576446533 \u001b[0m(-0.0376894474029541)\n",
            "     | > avg_log_mle:\u001b[92m 0.6982517242431641 \u001b[0m(-0.009733140468597412)\n",
            "     | > avg_loss_dur:\u001b[92m 2.2551510334014893 \u001b[0m(-0.027956247329711914)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_275.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 25/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:01:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:01:53 -- STEP: 0/11 -- GLOBAL_STEP: 275\u001b[0m\n",
            "     | > loss: 2.736175298690796  (2.736175298690796)\n",
            "     | > log_mle: 0.6927838325500488  (0.6927838325500488)\n",
            "     | > loss_dur: 2.043391466140747  (2.043391466140747)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.1652, device='cuda:0')  (tensor(5.1652, device='cuda:0'))\n",
            "     | > current_lr: 6.2499999999999995e-06 \n",
            "     | > step_time: 1.7155  (1.7154555320739746)\n",
            "     | > loader_time: 3.1839  (3.1838910579681396)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6586446762084961 \u001b[0m(+0.06640887260437012)\n",
            "     | > avg_loss:\u001b[92m 2.915060043334961 \u001b[0m(-0.03834271430969238)\n",
            "     | > avg_log_mle:\u001b[92m 0.6881412267684937 \u001b[0m(-0.01011049747467041)\n",
            "     | > avg_loss_dur:\u001b[92m 2.226918935775757 \u001b[0m(-0.028232097625732422)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_286.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 26/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:02:21) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6941394805908203 \u001b[0m(+0.03549480438232422)\n",
            "     | > avg_loss:\u001b[92m 2.8609957695007324 \u001b[0m(-0.054064273834228516)\n",
            "     | > avg_log_mle:\u001b[92m 0.6778246164321899 \u001b[0m(-0.010316610336303711)\n",
            "     | > avg_loss_dur:\u001b[92m 2.183171033859253 \u001b[0m(-0.043747901916503906)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_297.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 27/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:02:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:03:07 -- STEP: 3/11 -- GLOBAL_STEP: 300\u001b[0m\n",
            "     | > loss: 2.908109664916992  (2.864450693130493)\n",
            "     | > log_mle: 0.6726887226104736  (0.6713845729827881)\n",
            "     | > loss_dur: 2.2354209423065186  (2.193066120147705)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.3163, device='cuda:0')  (tensor(5.2648, device='cuda:0'))\n",
            "     | > current_lr: 6.75e-06 \n",
            "     | > step_time: 1.7734  (2.287282705307007)\n",
            "     | > loader_time: 0.0226  (0.03951581319173177)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8916199207305908 \u001b[0m(+0.1974804401397705)\n",
            "     | > avg_loss:\u001b[92m 2.817396402359009 \u001b[0m(-0.04359936714172363)\n",
            "     | > avg_log_mle:\u001b[92m 0.6673124432563782 \u001b[0m(-0.010512173175811768)\n",
            "     | > avg_loss_dur:\u001b[92m 2.1500840187072754 \u001b[0m(-0.03308701515197754)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_308.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 28/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:03:30) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.4539527893066406 \u001b[0m(+0.5623328685760498)\n",
            "     | > avg_loss:\u001b[92m 2.7492599487304688 \u001b[0m(-0.06813645362854004)\n",
            "     | > avg_log_mle:\u001b[92m 0.6566258668899536 \u001b[0m(-0.01068657636642456)\n",
            "     | > avg_loss_dur:\u001b[92m 2.0926342010498047 \u001b[0m(-0.0574498176574707)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_319.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 29/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:04:06) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:04:22 -- STEP: 6/11 -- GLOBAL_STEP: 325\u001b[0m\n",
            "     | > loss: 2.8326902389526367  (2.789127548535665)\n",
            "     | > log_mle: 0.638548731803894  (0.6455305218696594)\n",
            "     | > loss_dur: 2.194141387939453  (2.143596967061361)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.2078, device='cuda:0')  (tensor(5.1638, device='cuda:0'))\n",
            "     | > current_lr: 7.25e-06 \n",
            "     | > step_time: 0.6376  (1.2823985815048218)\n",
            "     | > loader_time: 0.0061  (0.016518473625183105)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8022451400756836 \u001b[0m(-0.651707649230957)\n",
            "     | > avg_loss:\u001b[92m 2.6932268142700195 \u001b[0m(-0.05603313446044922)\n",
            "     | > avg_log_mle:\u001b[92m 0.6457556486129761 \u001b[0m(-0.010870218276977539)\n",
            "     | > avg_loss_dur:\u001b[92m 2.047471046447754 \u001b[0m(-0.04516315460205078)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_330.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 30/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:04:36) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6590273380279541 \u001b[0m(-0.1432178020477295)\n",
            "     | > avg_loss:\u001b[92m 2.6162331104278564 \u001b[0m(-0.07699370384216309)\n",
            "     | > avg_log_mle:\u001b[92m 0.6346875429153442 \u001b[0m(-0.011068105697631836)\n",
            "     | > avg_loss_dur:\u001b[92m 1.9815455675125122 \u001b[0m(-0.0659254789352417)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_341.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 31/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:05:10) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:05:33 -- STEP: 9/11 -- GLOBAL_STEP: 350\u001b[0m\n",
            "     | > loss: 2.731618642807007  (2.681247419781155)\n",
            "     | > log_mle: 0.615483283996582  (0.618436747127109)\n",
            "     | > loss_dur: 2.116135358810425  (2.0628106594085693)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.0753, device='cuda:0')  (tensor(4.9992, device='cuda:0'))\n",
            "     | > current_lr: 7.75e-06 \n",
            "     | > step_time: 0.803  (1.6457808017730713)\n",
            "     | > loader_time: 0.0063  (0.020361926820543077)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5917909145355225 \u001b[0m(-0.06723642349243164)\n",
            "     | > avg_loss:\u001b[92m 2.5768208503723145 \u001b[0m(-0.03941226005554199)\n",
            "     | > avg_log_mle:\u001b[92m 0.6233960390090942 \u001b[0m(-0.01129150390625)\n",
            "     | > avg_loss_dur:\u001b[92m 1.9534249305725098 \u001b[0m(-0.02812063694000244)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_352.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 32/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:05:52) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6013762950897217 \u001b[0m(+0.009585380554199219)\n",
            "     | > avg_loss:\u001b[92m 2.497602939605713 \u001b[0m(-0.07921791076660156)\n",
            "     | > avg_log_mle:\u001b[92m 0.6119175553321838 \u001b[0m(-0.0114784836769104)\n",
            "     | > avg_loss_dur:\u001b[92m 1.8856854438781738 \u001b[0m(-0.06773948669433594)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_363.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 33/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:06:28) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6377685070037842 \u001b[0m(+0.0363922119140625)\n",
            "     | > avg_loss:\u001b[92m 2.3953957557678223 \u001b[0m(-0.10220718383789062)\n",
            "     | > avg_log_mle:\u001b[92m 0.6003451347351074 \u001b[0m(-0.011572420597076416)\n",
            "     | > avg_loss_dur:\u001b[92m 1.7950507402420044 \u001b[0m(-0.09063470363616943)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_374.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 34/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:07:03) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:07:09 -- STEP: 1/11 -- GLOBAL_STEP: 375\u001b[0m\n",
            "     | > loss: 2.3938820362091064  (2.3938820362091064)\n",
            "     | > log_mle: 0.5905395150184631  (0.5905395150184631)\n",
            "     | > loss_dur: 1.8033424615859985  (1.8033424615859985)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.4472, device='cuda:0')  (tensor(4.4472, device='cuda:0'))\n",
            "     | > current_lr: 8.5e-06 \n",
            "     | > step_time: 1.085  (1.0849709510803223)\n",
            "     | > loader_time: 0.0129  (0.012878179550170898)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.886580228805542 \u001b[0m(+0.2488117218017578)\n",
            "     | > avg_loss:\u001b[92m 2.3231794834136963 \u001b[0m(-0.07221627235412598)\n",
            "     | > avg_log_mle:\u001b[92m 0.5888001918792725 \u001b[0m(-0.011544942855834961)\n",
            "     | > avg_loss_dur:\u001b[92m 1.7343792915344238 \u001b[0m(-0.060671448707580566)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_385.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 35/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:07:39) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.0153000354766846 \u001b[0m(+0.12871980667114258)\n",
            "     | > avg_loss:\u001b[92m 2.281245708465576 \u001b[0m(-0.04193377494812012)\n",
            "     | > avg_log_mle:\u001b[92m 0.5774149894714355 \u001b[0m(-0.011385202407836914)\n",
            "     | > avg_loss_dur:\u001b[92m 1.703830599784851 \u001b[0m(-0.030548691749572754)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_396.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 36/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:08:10) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:08:26 -- STEP: 4/11 -- GLOBAL_STEP: 400\u001b[0m\n",
            "     | > loss: 2.363368511199951  (2.3150575160980225)\n",
            "     | > log_mle: 0.5611999034881592  (0.5632327497005463)\n",
            "     | > loss_dur: 1.802168607711792  (1.7518247067928314)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.2943, device='cuda:0')  (tensor(4.2171, device='cuda:0'))\n",
            "     | > current_lr: 9e-06 \n",
            "     | > step_time: 1.4357  (1.5086374282836914)\n",
            "     | > loader_time: 0.0273  (0.02484714984893799)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_400.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7257180213928223 \u001b[0m(-0.2895820140838623)\n",
            "     | > avg_loss:\u001b[92m 2.2141172885894775 \u001b[0m(-0.06712841987609863)\n",
            "     | > avg_log_mle:\u001b[92m 0.5662541389465332 \u001b[0m(-0.011160850524902344)\n",
            "     | > avg_loss_dur:\u001b[92m 1.6478631496429443 \u001b[0m(-0.05596745014190674)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_407.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 37/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:08:52) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.4000880718231201 \u001b[0m(+0.6743700504302979)\n",
            "     | > avg_loss:\u001b[92m 2.1964797973632812 \u001b[0m(-0.01763749122619629)\n",
            "     | > avg_log_mle:\u001b[92m 0.5554052591323853 \u001b[0m(-0.01084887981414795)\n",
            "     | > avg_loss_dur:\u001b[92m 1.6410744190216064 \u001b[0m(-0.006788730621337891)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_418.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 38/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:09:32) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:09:53 -- STEP: 7/11 -- GLOBAL_STEP: 425\u001b[0m\n",
            "     | > loss: 2.309905529022217  (2.235396044594901)\n",
            "     | > log_mle: 0.5243885517120361  (0.5362689409937177)\n",
            "     | > loss_dur: 1.7855170965194702  (1.6991270439965385)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.1608, device='cuda:0')  (tensor(4.0269, device='cuda:0'))\n",
            "     | > current_lr: 9.499999999999999e-06 \n",
            "     | > step_time: 0.8018  (2.1990775721413747)\n",
            "     | > loader_time: 0.0089  (0.037062883377075195)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6077430248260498 \u001b[0m(-0.7923450469970703)\n",
            "     | > avg_loss:\u001b[92m 2.1453957557678223 \u001b[0m(-0.051084041595458984)\n",
            "     | > avg_log_mle:\u001b[92m 0.5448681116104126 \u001b[0m(-0.010537147521972656)\n",
            "     | > avg_loss_dur:\u001b[92m 1.6005277633666992 \u001b[0m(-0.04054665565490723)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_429.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 39/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:10:06) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6181511878967285 \u001b[0m(+0.010408163070678711)\n",
            "     | > avg_loss:\u001b[92m 2.0912771224975586 \u001b[0m(-0.05411863327026367)\n",
            "     | > avg_log_mle:\u001b[92m 0.5345820784568787 \u001b[0m(-0.010286033153533936)\n",
            "     | > avg_loss_dur:\u001b[92m 1.5566949844360352 \u001b[0m(-0.04383277893066406)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_440.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 40/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:10:39) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:10:56 -- STEP: 10/11 -- GLOBAL_STEP: 450\u001b[0m\n",
            "     | > loss: 2.192638397216797  (2.151854395866394)\n",
            "     | > log_mle: 0.5011440515518188  (0.5120074272155761)\n",
            "     | > loss_dur: 1.6914944648742676  (1.639846956729889)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.9810, device='cuda:0')  (tensor(3.8485, device='cuda:0'))\n",
            "     | > current_lr: 9.999999999999999e-06 \n",
            "     | > step_time: 0.535  (1.1046260595321655)\n",
            "     | > loader_time: 0.0061  (0.0166428804397583)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6055788993835449 \u001b[0m(-0.012572288513183594)\n",
            "     | > avg_loss:\u001b[92m 2.0377628803253174 \u001b[0m(-0.05351424217224121)\n",
            "     | > avg_log_mle:\u001b[92m 0.5244042873382568 \u001b[0m(-0.010177791118621826)\n",
            "     | > avg_loss_dur:\u001b[92m 1.5133585929870605 \u001b[0m(-0.04333639144897461)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_451.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 41/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:11:07) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6152081489562988 \u001b[0m(+0.009629249572753906)\n",
            "     | > avg_loss:\u001b[92m 1.9999852180480957 \u001b[0m(-0.03777766227722168)\n",
            "     | > avg_log_mle:\u001b[92m 0.5142748951911926 \u001b[0m(-0.010129392147064209)\n",
            "     | > avg_loss_dur:\u001b[92m 1.4857103824615479 \u001b[0m(-0.027648210525512695)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_462.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 42/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:11:40) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6202640533447266 \u001b[0m(+0.005055904388427734)\n",
            "     | > avg_loss:\u001b[92m 1.9521980285644531 \u001b[0m(-0.04778718948364258)\n",
            "     | > avg_log_mle:\u001b[92m 0.504186749458313 \u001b[0m(-0.010088145732879639)\n",
            "     | > avg_loss_dur:\u001b[92m 1.4480112791061401 \u001b[0m(-0.037699103355407715)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_473.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 43/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:12:12) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:12:20 -- STEP: 2/11 -- GLOBAL_STEP: 475\u001b[0m\n",
            "     | > loss: 1.9602360725402832  (1.945326805114746)\n",
            "     | > log_mle: 0.48433250188827515  (0.48863445222377777)\n",
            "     | > loss_dur: 1.4759035110473633  (1.4566923379898071)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.4863, device='cuda:0')  (tensor(3.4390, device='cuda:0'))\n",
            "     | > current_lr: 1.075e-05 \n",
            "     | > step_time: 2.3005  (1.7912873029708862)\n",
            "     | > loader_time: 0.0228  (0.02130603790283203)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6367363929748535 \u001b[0m(+0.016472339630126953)\n",
            "     | > avg_loss:\u001b[92m 1.9325511455535889 \u001b[0m(-0.019646883010864258)\n",
            "     | > avg_log_mle:\u001b[92m 0.4942333400249481 \u001b[0m(-0.009953409433364868)\n",
            "     | > avg_loss_dur:\u001b[92m 1.4383177757263184 \u001b[0m(-0.009693503379821777)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_484.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 44/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:12:46) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6373007297515869 \u001b[0m(+0.0005643367767333984)\n",
            "     | > avg_loss:\u001b[92m 1.905055284500122 \u001b[0m(-0.027495861053466797)\n",
            "     | > avg_log_mle:\u001b[92m 0.48457783460617065 \u001b[0m(-0.009655505418777466)\n",
            "     | > avg_loss_dur:\u001b[92m 1.4204773902893066 \u001b[0m(-0.01784038543701172)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_495.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 45/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:13:18) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:13:33 -- STEP: 5/11 -- GLOBAL_STEP: 500\u001b[0m\n",
            "     | > loss: 1.967004418373108  (1.92970609664917)\n",
            "     | > log_mle: 0.46610698103904724  (0.4683107197284698)\n",
            "     | > loss_dur: 1.5008974075317383  (1.4613953590393067)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.5589, device='cuda:0')  (tensor(3.4560, device='cuda:0'))\n",
            "     | > current_lr: 1.125e-05 \n",
            "     | > step_time: 0.7145  (1.3961215496063233)\n",
            "     | > loader_time: 0.0155  (0.024258184432983398)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.895298957824707 \u001b[0m(+0.2579982280731201)\n",
            "     | > avg_loss:\u001b[92m 1.8875993490219116 \u001b[0m(-0.01745593547821045)\n",
            "     | > avg_log_mle:\u001b[92m 0.475292444229126 \u001b[0m(-0.009285390377044678)\n",
            "     | > avg_loss_dur:\u001b[92m 1.4123069047927856 \u001b[0m(-0.008170485496520996)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_506.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 46/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:13:47) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6225104331970215 \u001b[0m(-0.27278852462768555)\n",
            "     | > avg_loss:\u001b[92m 1.8422006368637085 \u001b[0m(-0.045398712158203125)\n",
            "     | > avg_log_mle:\u001b[92m 0.4663706123828888 \u001b[0m(-0.008921831846237183)\n",
            "     | > avg_loss_dur:\u001b[92m 1.375830054283142 \u001b[0m(-0.036476850509643555)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_517.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 47/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:14:23) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:14:43 -- STEP: 8/11 -- GLOBAL_STEP: 525\u001b[0m\n",
            "     | > loss: 2.0122132301330566  (1.9277366250753403)\n",
            "     | > log_mle: 0.433478981256485  (0.44455575942993164)\n",
            "     | > loss_dur: 1.578734278678894  (1.4831808805465698)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.7225, device='cuda:0')  (tensor(3.5354, device='cuda:0'))\n",
            "     | > current_lr: 1.1750000000000001e-05 \n",
            "     | > step_time: 0.7203  (1.7146575450897217)\n",
            "     | > loader_time: 0.0079  (0.030467689037322998)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6890425682067871 \u001b[0m(+0.06653213500976562)\n",
            "     | > avg_loss:\u001b[92m 1.8409218788146973 \u001b[0m(-0.0012787580490112305)\n",
            "     | > avg_log_mle:\u001b[92m 0.4579295217990875 \u001b[0m(-0.00844109058380127)\n",
            "     | > avg_loss_dur:\u001b[91m 1.3829923868179321 \u001b[0m(+0.007162332534790039)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_528.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 48/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:15:03) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.0019209384918213 \u001b[0m(+0.3128783702850342)\n",
            "     | > avg_loss:\u001b[92m 1.796198844909668 \u001b[0m(-0.0447230339050293)\n",
            "     | > avg_log_mle:\u001b[92m 0.44986218214035034 \u001b[0m(-0.008067339658737183)\n",
            "     | > avg_loss_dur:\u001b[92m 1.3463366031646729 \u001b[0m(-0.03665578365325928)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_539.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 49/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:15:41) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6951167583465576 \u001b[0m(-0.30680418014526367)\n",
            "     | > avg_loss:\u001b[92m 1.7795065641403198 \u001b[0m(-0.016692280769348145)\n",
            "     | > avg_log_mle:\u001b[92m 0.442075252532959 \u001b[0m(-0.007786929607391357)\n",
            "     | > avg_loss_dur:\u001b[92m 1.3374313116073608 \u001b[0m(-0.008905291557312012)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_550.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 50/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:16:18) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:16:28 -- STEP: 0/11 -- GLOBAL_STEP: 550\u001b[0m\n",
            "     | > loss: 1.6936733722686768  (1.6936733722686768)\n",
            "     | > log_mle: 0.42517566680908203  (0.42517566680908203)\n",
            "     | > loss_dur: 1.2684977054595947  (1.2684977054595947)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.1505, device='cuda:0')  (tensor(3.1505, device='cuda:0'))\n",
            "     | > current_lr: 1.2499999999999999e-05 \n",
            "     | > step_time: 3.4095  (3.4094738960266113)\n",
            "     | > loader_time: 6.8275  (6.8274946212768555)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.5987730026245117 \u001b[0m(+0.9036562442779541)\n",
            "     | > avg_loss:\u001b[92m 1.7541844844818115 \u001b[0m(-0.0253220796585083)\n",
            "     | > avg_log_mle:\u001b[92m 0.43442896008491516 \u001b[0m(-0.007646292448043823)\n",
            "     | > avg_loss_dur:\u001b[92m 1.3197555541992188 \u001b[0m(-0.01767575740814209)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_561.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 51/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:16:57) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 1.0737721920013428 \u001b[0m(-0.525000810623169)\n",
            "     | > avg_loss:\u001b[92m 1.7223389148712158 \u001b[0m(-0.0318455696105957)\n",
            "     | > avg_log_mle:\u001b[92m 0.4268663823604584 \u001b[0m(-0.007562577724456787)\n",
            "     | > avg_loss_dur:\u001b[92m 1.295472502708435 \u001b[0m(-0.02428305149078369)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_572.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 52/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:17:33) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:17:48 -- STEP: 3/11 -- GLOBAL_STEP: 575\u001b[0m\n",
            "     | > loss: 1.7825441360473633  (1.7551119327545166)\n",
            "     | > log_mle: 0.41156262159347534  (0.4101207454999288)\n",
            "     | > loss_dur: 1.3709815740585327  (1.3449912071228027)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.4296, device='cuda:0')  (tensor(3.3482, device='cuda:0'))\n",
            "     | > current_lr: 1.3e-05 \n",
            "     | > step_time: 1.7496  (2.719503402709961)\n",
            "     | > loader_time: 0.0679  (0.05880546569824219)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6921260356903076 \u001b[0m(-0.38164615631103516)\n",
            "     | > avg_loss:\u001b[92m 1.6784855127334595 \u001b[0m(-0.04385340213775635)\n",
            "     | > avg_log_mle:\u001b[92m 0.41952046751976013 \u001b[0m(-0.007345914840698242)\n",
            "     | > avg_loss_dur:\u001b[92m 1.258965015411377 \u001b[0m(-0.036507487297058105)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_583.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 53/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:18:08) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6396572589874268 \u001b[0m(-0.05246877670288086)\n",
            "     | > avg_loss:\u001b[92m 1.6499748229980469 \u001b[0m(-0.028510689735412598)\n",
            "     | > avg_log_mle:\u001b[92m 0.41219907999038696 \u001b[0m(-0.007321387529373169)\n",
            "     | > avg_loss_dur:\u001b[92m 1.2377756834030151 \u001b[0m(-0.021189332008361816)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_594.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 54/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:18:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:19:00 -- STEP: 6/11 -- GLOBAL_STEP: 600\u001b[0m\n",
            "     | > loss: 1.7626988887786865  (1.7208118637402852)\n",
            "     | > log_mle: 0.3869083523750305  (0.3931250075499217)\n",
            "     | > loss_dur: 1.3757904767990112  (1.327686866124471)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.4442, device='cuda:0')  (tensor(3.3210, device='cuda:0'))\n",
            "     | > current_lr: 1.35e-05 \n",
            "     | > step_time: 0.6471  (2.025855223337809)\n",
            "     | > loader_time: 0.0079  (0.03299546241760254)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_600.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7172853946685791 \u001b[0m(+0.07762813568115234)\n",
            "     | > avg_loss:\u001b[92m 1.6110515594482422 \u001b[0m(-0.03892326354980469)\n",
            "     | > avg_log_mle:\u001b[92m 0.4049902558326721 \u001b[0m(-0.007208824157714844)\n",
            "     | > avg_loss_dur:\u001b[92m 1.2060612440109253 \u001b[0m(-0.031714439392089844)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_605.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 55/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:19:28) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6830844879150391 \u001b[0m(-0.03420090675354004)\n",
            "     | > avg_loss:\u001b[92m 1.5444144010543823 \u001b[0m(-0.06663715839385986)\n",
            "     | > avg_log_mle:\u001b[92m 0.39784693717956543 \u001b[0m(-0.0071433186531066895)\n",
            "     | > avg_loss_dur:\u001b[92m 1.146567463874817 \u001b[0m(-0.0594937801361084)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_616.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 56/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:20:17) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:20:39 -- STEP: 9/11 -- GLOBAL_STEP: 625\u001b[0m\n",
            "     | > loss: 1.7005054950714111  (1.6699886454476252)\n",
            "     | > log_mle: 0.37462252378463745  (0.3744464914004008)\n",
            "     | > loss_dur: 1.3258830308914185  (1.2955421606699626)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.2358, device='cuda:0')  (tensor(3.2180, device='cuda:0'))\n",
            "     | > current_lr: 1.4e-05 \n",
            "     | > step_time: 0.8037  (1.5526023705800374)\n",
            "     | > loader_time: 0.0064  (0.020058287514580622)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.4478294849395752 \u001b[0m(+0.7647449970245361)\n",
            "     | > avg_loss:\u001b[92m 1.5183374881744385 \u001b[0m(-0.026076912879943848)\n",
            "     | > avg_log_mle:\u001b[92m 0.3906363248825073 \u001b[0m(-0.0072106122970581055)\n",
            "     | > avg_loss_dur:\u001b[92m 1.1277011632919312 \u001b[0m(-0.018866300582885742)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_627.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 57/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:20:56) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.629631519317627 \u001b[0m(-0.8181979656219482)\n",
            "     | > avg_loss:\u001b[92m 1.4988973140716553 \u001b[0m(-0.019440174102783203)\n",
            "     | > avg_log_mle:\u001b[92m 0.38356250524520874 \u001b[0m(-0.007073819637298584)\n",
            "     | > avg_loss_dur:\u001b[92m 1.1153348684310913 \u001b[0m(-0.012366294860839844)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_638.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 58/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:21:30) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.2647502422332764 \u001b[0m(+0.6351187229156494)\n",
            "     | > avg_loss:\u001b[92m 1.4712350368499756 \u001b[0m(-0.027662277221679688)\n",
            "     | > avg_log_mle:\u001b[92m 0.3763473629951477 \u001b[0m(-0.007215142250061035)\n",
            "     | > avg_loss_dur:\u001b[92m 1.094887614250183 \u001b[0m(-0.020447254180908203)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_649.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 59/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:22:09) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:22:16 -- STEP: 1/11 -- GLOBAL_STEP: 650\u001b[0m\n",
            "     | > loss: 1.506007194519043  (1.506007194519043)\n",
            "     | > log_mle: 0.36252617835998535  (0.36252617835998535)\n",
            "     | > loss_dur: 1.1434810161590576  (1.1434810161590576)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.8529, device='cuda:0')  (tensor(2.8529, device='cuda:0'))\n",
            "     | > current_lr: 1.475e-05 \n",
            "     | > step_time: 1.7306  (1.7306180000305176)\n",
            "     | > loader_time: 0.0245  (0.024482011795043945)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6294231414794922 \u001b[0m(-0.6353271007537842)\n",
            "     | > avg_loss:\u001b[92m 1.4492368698120117 \u001b[0m(-0.021998167037963867)\n",
            "     | > avg_log_mle:\u001b[92m 0.369212806224823 \u001b[0m(-0.007134556770324707)\n",
            "     | > avg_loss_dur:\u001b[92m 1.080024003982544 \u001b[0m(-0.01486361026763916)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_660.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 60/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:22:42) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7254683971405029 \u001b[0m(+0.09604525566101074)\n",
            "     | > avg_loss:\u001b[92m 1.434865951538086 \u001b[0m(-0.014370918273925781)\n",
            "     | > avg_log_mle:\u001b[92m 0.3620991110801697 \u001b[0m(-0.00711369514465332)\n",
            "     | > avg_loss_dur:\u001b[92m 1.0727667808532715 \u001b[0m(-0.007257223129272461)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_671.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 61/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:23:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:23:25 -- STEP: 4/11 -- GLOBAL_STEP: 675\u001b[0m\n",
            "     | > loss: 1.5275366306304932  (1.4838877022266388)\n",
            "     | > log_mle: 0.34122544527053833  (0.34252282977104187)\n",
            "     | > loss_dur: 1.18631112575531  (1.141364872455597)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.8844, device='cuda:0')  (tensor(2.8650, device='cuda:0'))\n",
            "     | > current_lr: 1.525e-05 \n",
            "     | > step_time: 1.9066  (1.6758984923362732)\n",
            "     | > loader_time: 0.0136  (0.020929694175720215)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7333598136901855 \u001b[0m(+0.007891416549682617)\n",
            "     | > avg_loss:\u001b[92m 1.412712574005127 \u001b[0m(-0.022153377532958984)\n",
            "     | > avg_log_mle:\u001b[92m 0.3551700711250305 \u001b[0m(-0.00692903995513916)\n",
            "     | > avg_loss_dur:\u001b[92m 1.0575424432754517 \u001b[0m(-0.015224337577819824)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_682.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 62/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:23:44) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.2656280994415283 \u001b[0m(+0.5322682857513428)\n",
            "     | > avg_loss:\u001b[92m 1.3905550241470337 \u001b[0m(-0.02215754985809326)\n",
            "     | > avg_log_mle:\u001b[92m 0.348019003868103 \u001b[0m(-0.00715106725692749)\n",
            "     | > avg_loss_dur:\u001b[92m 1.0425360202789307 \u001b[0m(-0.015006422996520996)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_693.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 63/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:24:24) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:24:42 -- STEP: 7/11 -- GLOBAL_STEP: 700\u001b[0m\n",
            "     | > loss: 1.5034849643707275  (1.4615219831466675)\n",
            "     | > log_mle: 0.3122386336326599  (0.3244792308126177)\n",
            "     | > loss_dur: 1.1912462711334229  (1.1370427438191004)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.8801, device='cuda:0')  (tensor(2.7646, device='cuda:0'))\n",
            "     | > current_lr: 1.575e-05 \n",
            "     | > step_time: 0.6395  (1.7377951826368059)\n",
            "     | > loader_time: 0.0068  (0.03434641020638602)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7555317878723145 \u001b[0m(-0.5100963115692139)\n",
            "     | > avg_loss:\u001b[92m 1.3709239959716797 \u001b[0m(-0.019631028175354004)\n",
            "     | > avg_log_mle:\u001b[92m 0.34104418754577637 \u001b[0m(-0.00697481632232666)\n",
            "     | > avg_loss_dur:\u001b[92m 1.0298798084259033 \u001b[0m(-0.012656211853027344)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_704.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 64/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:25:00) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6386842727661133 \u001b[0m(-0.11684751510620117)\n",
            "     | > avg_loss:\u001b[92m 1.339360237121582 \u001b[0m(-0.031563758850097656)\n",
            "     | > avg_log_mle:\u001b[92m 0.33400648832321167 \u001b[0m(-0.007037699222564697)\n",
            "     | > avg_loss_dur:\u001b[92m 1.0053536891937256 \u001b[0m(-0.024526119232177734)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_715.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 65/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:25:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:25:57 -- STEP: 10/11 -- GLOBAL_STEP: 725\u001b[0m\n",
            "     | > loss: 1.4578745365142822  (1.4297897815704346)\n",
            "     | > log_mle: 0.29474806785583496  (0.3071719706058502)\n",
            "     | > loss_dur: 1.1631264686584473  (1.122617816925049)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.8634, device='cuda:0')  (tensor(2.8054, device='cuda:0'))\n",
            "     | > current_lr: 1.625e-05 \n",
            "     | > step_time: 0.405  (1.4597134590148926)\n",
            "     | > loader_time: 0.0046  (0.02108449935913086)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7338213920593262 \u001b[0m(+0.09513711929321289)\n",
            "     | > avg_loss:\u001b[92m 1.32236909866333 \u001b[0m(-0.016991138458251953)\n",
            "     | > avg_log_mle:\u001b[92m 0.3271101117134094 \u001b[0m(-0.006896376609802246)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9952590465545654 \u001b[0m(-0.010094642639160156)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_726.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 66/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:26:11) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7344920635223389 \u001b[0m(+0.0006706714630126953)\n",
            "     | > avg_loss:\u001b[92m 1.3080165386199951 \u001b[0m(-0.014352560043334961)\n",
            "     | > avg_log_mle:\u001b[92m 0.320235013961792 \u001b[0m(-0.006875097751617432)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9877815246582031 \u001b[0m(-0.007477521896362305)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_737.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 67/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:26:54) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6548967361450195 \u001b[0m(-0.07959532737731934)\n",
            "     | > avg_loss:\u001b[92m 1.2894970178604126 \u001b[0m(-0.01851952075958252)\n",
            "     | > avg_log_mle:\u001b[92m 0.31356412172317505 \u001b[0m(-0.006670892238616943)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9759328961372375 \u001b[0m(-0.011848628520965576)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_748.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 68/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:27:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:27:42 -- STEP: 2/11 -- GLOBAL_STEP: 750\u001b[0m\n",
            "     | > loss: 1.3097741603851318  (1.3066202402114868)\n",
            "     | > log_mle: 0.2863468527793884  (0.2915199398994446)\n",
            "     | > loss_dur: 1.0234273672103882  (1.0151003003120422)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.5827, device='cuda:0')  (tensor(2.5070, device='cuda:0'))\n",
            "     | > current_lr: 1.7e-05 \n",
            "     | > step_time: 3.487  (2.829827666282654)\n",
            "     | > loader_time: 0.0251  (0.023565292358398438)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7475793361663818 \u001b[0m(+0.0926826000213623)\n",
            "     | > avg_loss:\u001b[92m 1.2767083644866943 \u001b[0m(-0.012788653373718262)\n",
            "     | > avg_log_mle:\u001b[92m 0.30693066120147705 \u001b[0m(-0.006633460521697998)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9697777628898621 \u001b[0m(-0.006155133247375488)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_759.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 69/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:28:07) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.4448761940002441 \u001b[0m(+0.6972968578338623)\n",
            "     | > avg_loss:\u001b[92m 1.253892183303833 \u001b[0m(-0.022816181182861328)\n",
            "     | > avg_log_mle:\u001b[92m 0.300173819065094 \u001b[0m(-0.006756842136383057)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9537184238433838 \u001b[0m(-0.01605933904647827)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_770.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 70/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:28:47) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:29:03 -- STEP: 5/11 -- GLOBAL_STEP: 775\u001b[0m\n",
            "     | > loss: 1.327936053276062  (1.2969694137573242)\n",
            "     | > log_mle: 0.27612102031707764  (0.27802798748016355)\n",
            "     | > loss_dur: 1.0518150329589844  (1.0189414143562316)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.4828, device='cuda:0')  (tensor(2.4031, device='cuda:0'))\n",
            "     | > current_lr: 1.7500000000000002e-05 \n",
            "     | > step_time: 0.7003  (1.7208954334259032)\n",
            "     | > loader_time: 0.0145  (0.02695293426513672)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6254644393920898 \u001b[0m(-0.8194117546081543)\n",
            "     | > avg_loss:\u001b[92m 1.240951657295227 \u001b[0m(-0.012940526008605957)\n",
            "     | > avg_log_mle:\u001b[92m 0.2935100793838501 \u001b[0m(-0.0066637396812438965)\n",
            "     | > avg_loss_dur:\u001b[92m 0.947441577911377 \u001b[0m(-0.006276845932006836)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_781.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 71/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:29:21) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6863148212432861 \u001b[0m(+0.06085038185119629)\n",
            "     | > avg_loss:\u001b[92m 1.230483889579773 \u001b[0m(-0.010467767715454102)\n",
            "     | > avg_log_mle:\u001b[92m 0.2865726947784424 \u001b[0m(-0.006937384605407715)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9439111948013306 \u001b[0m(-0.0035303831100463867)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_792.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 72/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:29:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:30:17 -- STEP: 8/11 -- GLOBAL_STEP: 800\u001b[0m\n",
            "     | > loss: 1.330127477645874  (1.27958245575428)\n",
            "     | > log_mle: 0.24743252992630005  (0.2589915990829468)\n",
            "     | > loss_dur: 1.0826950073242188  (1.0205908566713333)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.6946, device='cuda:0')  (tensor(2.4883, device='cuda:0'))\n",
            "     | > current_lr: 1.8e-05 \n",
            "     | > step_time: 0.6828  (1.4902763366699219)\n",
            "     | > loader_time: 0.0063  (0.018880873918533325)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_800.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.972482442855835 \u001b[0m(+1.2861676216125488)\n",
            "     | > avg_loss:\u001b[92m 1.2132351398468018 \u001b[0m(-0.01724874973297119)\n",
            "     | > avg_log_mle:\u001b[92m 0.2800471782684326 \u001b[0m(-0.006525516510009766)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9331879615783691 \u001b[0m(-0.010723233222961426)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_803.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 73/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:30:38) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 1.539867639541626 \u001b[0m(-0.432614803314209)\n",
            "     | > avg_loss:\u001b[92m 1.194819450378418 \u001b[0m(-0.01841568946838379)\n",
            "     | > avg_log_mle:\u001b[92m 0.2733660340309143 \u001b[0m(-0.0066811442375183105)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9214534759521484 \u001b[0m(-0.011734485626220703)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_814.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 74/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:31:30) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7449064254760742 \u001b[0m(-0.7949612140655518)\n",
            "     | > avg_loss:\u001b[92m 1.1854262351989746 \u001b[0m(-0.00939321517944336)\n",
            "     | > avg_log_mle:\u001b[92m 0.2669917345046997 \u001b[0m(-0.0063742995262146)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9184345006942749 \u001b[0m(-0.003018975257873535)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_825.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 75/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:32:06) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:32:17 -- STEP: 0/11 -- GLOBAL_STEP: 825\u001b[0m\n",
            "     | > loss: 1.091773271560669  (1.091773271560669)\n",
            "     | > log_mle: 0.2419789433479309  (0.2419789433479309)\n",
            "     | > loss_dur: 0.849794328212738  (0.849794328212738)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.0947, device='cuda:0')  (tensor(2.0947, device='cuda:0'))\n",
            "     | > current_lr: 1.875e-05 \n",
            "     | > step_time: 3.3883  (3.3883354663848877)\n",
            "     | > loader_time: 7.4819  (7.481889486312866)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 2.113827705383301 \u001b[0m(+1.3689212799072266)\n",
            "     | > avg_loss:\u001b[92m 1.1728155612945557 \u001b[0m(-0.012610673904418945)\n",
            "     | > avg_log_mle:\u001b[92m 0.2604672312736511 \u001b[0m(-0.006524503231048584)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9123483300209045 \u001b[0m(-0.006086170673370361)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_836.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 76/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:32:47) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6259386539459229 \u001b[0m(-1.487889051437378)\n",
            "     | > avg_loss:\u001b[92m 1.1530396938323975 \u001b[0m(-0.019775867462158203)\n",
            "     | > avg_log_mle:\u001b[92m 0.25416356325149536 \u001b[0m(-0.006303668022155762)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8988761901855469 \u001b[0m(-0.013472139835357666)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_847.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 77/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:33:28) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:33:42 -- STEP: 3/11 -- GLOBAL_STEP: 850\u001b[0m\n",
            "     | > loss: 1.161747694015503  (1.1469775040944417)\n",
            "     | > log_mle: 0.23427778482437134  (0.2309830586115519)\n",
            "     | > loss_dur: 0.9274699091911316  (0.9159944256146749)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.4400, device='cuda:0')  (tensor(2.2810, device='cuda:0'))\n",
            "     | > current_lr: 1.925e-05 \n",
            "     | > step_time: 3.0005  (2.997761090596517)\n",
            "     | > loader_time: 0.0441  (0.04366803169250488)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7558684349060059 \u001b[0m(+0.129929780960083)\n",
            "     | > avg_loss:\u001b[92m 1.1414194107055664 \u001b[0m(-0.011620283126831055)\n",
            "     | > avg_log_mle:\u001b[92m 0.24782037734985352 \u001b[0m(-0.006343185901641846)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8935989737510681 \u001b[0m(-0.00527721643447876)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_858.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 78/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:34:05) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.5686242580413818 \u001b[0m(+0.812755823135376)\n",
            "     | > avg_loss:\u001b[92m 1.1296112537384033 \u001b[0m(-0.011808156967163086)\n",
            "     | > avg_log_mle:\u001b[92m 0.24174010753631592 \u001b[0m(-0.006080269813537598)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8878710865974426 \u001b[0m(-0.005727887153625488)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_869.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 79/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:34:42) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:34:59 -- STEP: 6/11 -- GLOBAL_STEP: 875\u001b[0m\n",
            "     | > loss: 1.1685504913330078  (1.1363088885943096)\n",
            "     | > log_mle: 0.20958900451660156  (0.21590895454088846)\n",
            "     | > loss_dur: 0.9589614868164062  (0.9203999439875284)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.4019, device='cuda:0')  (tensor(2.3619, device='cuda:0'))\n",
            "     | > current_lr: 1.975e-05 \n",
            "     | > step_time: 0.6633  (2.0865830183029175)\n",
            "     | > loader_time: 0.0066  (0.03897599379221598)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.799013614654541 \u001b[0m(-0.7696106433868408)\n",
            "     | > avg_loss:\u001b[92m 1.1092166900634766 \u001b[0m(-0.020394563674926758)\n",
            "     | > avg_log_mle:\u001b[92m 0.2360149621963501 \u001b[0m(-0.00572514533996582)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8732017874717712 \u001b[0m(-0.014669299125671387)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_880.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 80/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:35:19) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.9577655792236328 \u001b[0m(+0.1587519645690918)\n",
            "     | > avg_loss:\u001b[92m 1.0935558080673218 \u001b[0m(-0.015660881996154785)\n",
            "     | > avg_log_mle:\u001b[92m 0.23011112213134766 \u001b[0m(-0.005903840065002441)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8634446859359741 \u001b[0m(-0.00975710153579712)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_891.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 81/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:36:06) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:36:23 -- STEP: 9/11 -- GLOBAL_STEP: 900\u001b[0m\n",
            "     | > loss: 1.1472821235656738  (1.1171040667427912)\n",
            "     | > log_mle: 0.20008349418640137  (0.20004710886213514)\n",
            "     | > loss_dur: 0.9471985697746277  (0.917056938012441)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.0627, device='cuda:0')  (tensor(2.7158, device='cuda:0'))\n",
            "     | > current_lr: 2.025e-05 \n",
            "     | > step_time: 0.9493  (1.2697083950042725)\n",
            "     | > loader_time: 0.0124  (0.017532295650906034)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7733392715454102 \u001b[0m(-0.18442630767822266)\n",
            "     | > avg_loss:\u001b[92m 1.0798546075820923 \u001b[0m(-0.013701200485229492)\n",
            "     | > avg_log_mle:\u001b[92m 0.22406727075576782 \u001b[0m(-0.006043851375579834)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8557873368263245 \u001b[0m(-0.007657349109649658)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_902.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 82/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:36:41) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8283882141113281 \u001b[0m(+0.05504894256591797)\n",
            "     | > avg_loss:\u001b[92m 1.0613069534301758 \u001b[0m(-0.018547654151916504)\n",
            "     | > avg_log_mle:\u001b[92m 0.2182176113128662 \u001b[0m(-0.005849659442901611)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8430893421173096 \u001b[0m(-0.012697994709014893)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_913.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 83/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:37:17) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6849522590637207 \u001b[0m(-0.14343595504760742)\n",
            "     | > avg_loss:\u001b[92m 1.0491127967834473 \u001b[0m(-0.012194156646728516)\n",
            "     | > avg_log_mle:\u001b[92m 0.21240383386611938 \u001b[0m(-0.005813777446746826)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8367090225219727 \u001b[0m(-0.006380319595336914)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_924.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 84/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:38:05) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:38:15 -- STEP: 1/11 -- GLOBAL_STEP: 925\u001b[0m\n",
            "     | > loss: 1.0243184566497803  (1.0243184566497803)\n",
            "     | > log_mle: 0.18966567516326904  (0.18966567516326904)\n",
            "     | > loss_dur: 0.834652841091156  (0.834652841091156)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.9222, device='cuda:0')  (tensor(1.9222, device='cuda:0'))\n",
            "     | > current_lr: 2.1e-05 \n",
            "     | > step_time: 1.4769  (1.476935863494873)\n",
            "     | > loader_time: 0.0254  (0.025363922119140625)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.0205879211425781 \u001b[0m(+0.3356356620788574)\n",
            "     | > avg_loss:\u001b[92m 1.0339741706848145 \u001b[0m(-0.015138626098632812)\n",
            "     | > avg_log_mle:\u001b[92m 0.20685631036758423 \u001b[0m(-0.005547523498535156)\n",
            "     | > avg_loss_dur:\u001b[92m 0.827117919921875 \u001b[0m(-0.009591102600097656)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_935.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 85/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:38:44) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8512709140777588 \u001b[0m(-0.16931700706481934)\n",
            "     | > avg_loss:\u001b[92m 1.0194201469421387 \u001b[0m(-0.014554023742675781)\n",
            "     | > avg_log_mle:\u001b[92m 0.20129287242889404 \u001b[0m(-0.0055634379386901855)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8181272149085999 \u001b[0m(-0.008990705013275146)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_946.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 86/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:39:21) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:39:37 -- STEP: 4/11 -- GLOBAL_STEP: 950\u001b[0m\n",
            "     | > loss: 1.0454399585723877  (1.0082340091466904)\n",
            "     | > log_mle: 0.17547577619552612  (0.1754150092601776)\n",
            "     | > loss_dur: 0.8699642419815063  (0.832819014787674)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.1960, device='cuda:0')  (tensor(2.0959, device='cuda:0'))\n",
            "     | > current_lr: 2.15e-05 \n",
            "     | > step_time: 3.1664  (2.7524659037590027)\n",
            "     | > loader_time: 0.042  (0.038472771644592285)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7769267559051514 \u001b[0m(-0.07434415817260742)\n",
            "     | > avg_loss:\u001b[92m 1.0018343925476074 \u001b[0m(-0.01758575439453125)\n",
            "     | > avg_log_mle:\u001b[92m 0.19584989547729492 \u001b[0m(-0.005442976951599121)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8059844374656677 \u001b[0m(-0.012142777442932129)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_957.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 87/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:40:03) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6564195156097412 \u001b[0m(-0.12050724029541016)\n",
            "     | > avg_loss:\u001b[92m 0.9800487160682678 \u001b[0m(-0.0217856764793396)\n",
            "     | > avg_log_mle:\u001b[92m 0.19017094373703003 \u001b[0m(-0.005678951740264893)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7898777723312378 \u001b[0m(-0.01610666513442993)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_968.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 88/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:40:42) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:41:02 -- STEP: 7/11 -- GLOBAL_STEP: 975\u001b[0m\n",
            "     | > loss: 1.0314605236053467  (0.9987977572849819)\n",
            "     | > log_mle: 0.151269793510437  (0.1617808597428458)\n",
            "     | > loss_dur: 0.8801907896995544  (0.8370169060570853)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.6897, device='cuda:0')  (tensor(3.2519, device='cuda:0'))\n",
            "     | > current_lr: 2.2e-05 \n",
            "     | > step_time: 0.6494  (1.7353411742619105)\n",
            "     | > loader_time: 0.0072  (0.032015596117292135)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7882113456726074 \u001b[0m(+0.1317918300628662)\n",
            "     | > avg_loss:\u001b[92m 0.9654243588447571 \u001b[0m(-0.014624357223510742)\n",
            "     | > avg_log_mle:\u001b[92m 0.1862945556640625 \u001b[0m(-0.0038763880729675293)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7791298031806946 \u001b[0m(-0.010747969150543213)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_979.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 89/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:41:20) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6385750770568848 \u001b[0m(-0.14963626861572266)\n",
            "     | > avg_loss:\u001b[92m 0.9563020467758179 \u001b[0m(-0.009122312068939209)\n",
            "     | > avg_log_mle:\u001b[92m 0.18029320240020752 \u001b[0m(-0.0060013532638549805)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7760088443756104 \u001b[0m(-0.0031209588050842285)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_990.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 90/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:42:01) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:42:31 -- STEP: 10/11 -- GLOBAL_STEP: 1000\u001b[0m\n",
            "     | > loss: 0.9916360378265381  (0.9797033250331879)\n",
            "     | > log_mle: 0.13455438613891602  (0.14768449664115907)\n",
            "     | > loss_dur: 0.8570816516876221  (0.8320188283920288)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.1436, device='cuda:0')  (tensor(2.3623, device='cuda:0'))\n",
            "     | > current_lr: 2.25e-05 \n",
            "     | > step_time: 0.5646  (1.9727838516235352)\n",
            "     | > loader_time: 0.0069  (0.16850728988647462)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_1000.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6684057712554932 \u001b[0m(+0.0298306941986084)\n",
            "     | > avg_loss:\u001b[92m 0.941575288772583 \u001b[0m(-0.014726758003234863)\n",
            "     | > avg_log_mle:\u001b[92m 0.17535853385925293 \u001b[0m(-0.00493466854095459)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7662167549133301 \u001b[0m(-0.009792089462280273)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1001.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 91/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:42:54) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7609527111053467 \u001b[0m(+0.09254693984985352)\n",
            "     | > avg_loss:\u001b[92m 0.9235170483589172 \u001b[0m(-0.01805824041366577)\n",
            "     | > avg_log_mle:\u001b[92m 0.170302152633667 \u001b[0m(-0.0050563812255859375)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7532148957252502 \u001b[0m(-0.013001859188079834)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1012.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 92/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:43:33) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8961029052734375 \u001b[0m(+0.13515019416809082)\n",
            "     | > avg_loss:\u001b[92m 0.919025719165802 \u001b[0m(-0.004491329193115234)\n",
            "     | > avg_log_mle:\u001b[92m 0.16558486223220825 \u001b[0m(-0.00471729040145874)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7534408569335938 \u001b[0m(+0.00022596120834350586)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1023.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 93/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:44:11) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:44:21 -- STEP: 2/11 -- GLOBAL_STEP: 1025\u001b[0m\n",
            "     | > loss: 0.9034191370010376  (0.9014464318752289)\n",
            "     | > log_mle: 0.13161230087280273  (0.13601398468017578)\n",
            "     | > loss_dur: 0.7718068361282349  (0.7654324471950531)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.9532, device='cuda:0')  (tensor(1.9362, device='cuda:0'))\n",
            "     | > current_lr: 2.3250000000000003e-05 \n",
            "     | > step_time: 3.4855  (2.548803687095642)\n",
            "     | > loader_time: 0.0439  (0.04321944713592529)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.5708532333374023 \u001b[0m(+0.6747503280639648)\n",
            "     | > avg_loss:\u001b[92m 0.9037255644798279 \u001b[0m(-0.015300154685974121)\n",
            "     | > avg_log_mle:\u001b[92m 0.16100049018859863 \u001b[0m(-0.004584372043609619)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7427250742912292 \u001b[0m(-0.010715782642364502)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1034.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 94/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:44:58) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.655172348022461 \u001b[0m(+0.0843191146850586)\n",
            "     | > avg_loss:\u001b[92m 0.8932566046714783 \u001b[0m(-0.01046895980834961)\n",
            "     | > avg_log_mle:\u001b[92m 0.15674728155136108 \u001b[0m(-0.004253208637237549)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7365093231201172 \u001b[0m(-0.0062157511711120605)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1045.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 95/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:45:39) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:45:56 -- STEP: 5/11 -- GLOBAL_STEP: 1050\u001b[0m\n",
            "     | > loss: 0.9189647436141968  (0.8972875595092773)\n",
            "     | > log_mle: 0.1274573802947998  (0.12828739881515502)\n",
            "     | > loss_dur: 0.791507363319397  (0.7690001606941224)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.8153, device='cuda:0')  (tensor(2.1556, device='cuda:0'))\n",
            "     | > current_lr: 2.375e-05 \n",
            "     | > step_time: 1.8854  (2.338971185684204)\n",
            "     | > loader_time: 0.0474  (0.03558659553527832)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8198206424713135 \u001b[0m(-0.8353517055511475)\n",
            "     | > avg_loss:\u001b[92m 0.8859632015228271 \u001b[0m(-0.007293403148651123)\n",
            "     | > avg_log_mle:\u001b[92m 0.15155762434005737 \u001b[0m(-0.005189657211303711)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7344055771827698 \u001b[0m(-0.002103745937347412)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1056.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 96/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:46:14) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8278107643127441 \u001b[0m(+0.007990121841430664)\n",
            "     | > avg_loss:\u001b[92m 0.8684461116790771 \u001b[0m(-0.01751708984375)\n",
            "     | > avg_log_mle:\u001b[92m 0.1475258469581604 \u001b[0m(-0.004031777381896973)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7209202647209167 \u001b[0m(-0.013485312461853027)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1067.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 97/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:46:55) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:47:19 -- STEP: 8/11 -- GLOBAL_STEP: 1075\u001b[0m\n",
            "     | > loss: 0.9207313656806946  (0.8912309110164642)\n",
            "     | > log_mle: 0.10426658391952515  (0.11495697498321533)\n",
            "     | > loss_dur: 0.8164647817611694  (0.7762739360332489)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.3848, device='cuda:0')  (tensor(2.1228, device='cuda:0'))\n",
            "     | > current_lr: 2.425e-05 \n",
            "     | > step_time: 0.7084  (1.2012394964694977)\n",
            "     | > loader_time: 0.0181  (0.01934337615966797)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.9967441558837891 \u001b[0m(+0.16893339157104492)\n",
            "     | > avg_loss:\u001b[92m 0.8659585118293762 \u001b[0m(-0.0024875998497009277)\n",
            "     | > avg_log_mle:\u001b[92m 0.1427658200263977 \u001b[0m(-0.004760026931762695)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7231926918029785 \u001b[0m(+0.0022724270820617676)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1078.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 98/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:47:39) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8336696624755859 \u001b[0m(-0.16307449340820312)\n",
            "     | > avg_loss:\u001b[92m 0.851874589920044 \u001b[0m(-0.014083921909332275)\n",
            "     | > avg_log_mle:\u001b[92m 0.13893091678619385 \u001b[0m(-0.0038349032402038574)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7129436731338501 \u001b[0m(-0.010249018669128418)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1089.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 99/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:48:12) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8012971878051758 \u001b[0m(-0.032372474670410156)\n",
            "     | > avg_loss:\u001b[92m 0.8332452774047852 \u001b[0m(-0.01862931251525879)\n",
            "     | > avg_log_mle:\u001b[92m 0.134840190410614 \u001b[0m(-0.004090726375579834)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6984050869941711 \u001b[0m(-0.014538586139678955)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1100.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 100/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:48:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:48:53 -- STEP: 0/11 -- GLOBAL_STEP: 1100\u001b[0m\n",
            "     | > loss: 0.7607441544532776  (0.7607441544532776)\n",
            "     | > log_mle: 0.10169059038162231  (0.10169059038162231)\n",
            "     | > loss_dur: 0.6590535640716553  (0.6590535640716553)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.6959, device='cuda:0')  (tensor(1.6959, device='cuda:0'))\n",
            "     | > current_lr: 2.4999999999999998e-05 \n",
            "     | > step_time: 1.8943  (1.8942866325378418)\n",
            "     | > loader_time: 3.1752  (3.175187587738037)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.532616376876831 \u001b[0m(+0.7313191890716553)\n",
            "     | > avg_loss:\u001b[92m 0.8200758695602417 \u001b[0m(-0.013169407844543457)\n",
            "     | > avg_log_mle:\u001b[92m 0.1300029754638672 \u001b[0m(-0.004837214946746826)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6900728940963745 \u001b[0m(-0.00833219289779663)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1111.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 101/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:49:31) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7691135406494141 \u001b[0m(-0.763502836227417)\n",
            "     | > avg_loss:\u001b[92m 0.8016974925994873 \u001b[0m(-0.018378376960754395)\n",
            "     | > avg_log_mle:\u001b[92m 0.12620067596435547 \u001b[0m(-0.0038022994995117188)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6754968166351318 \u001b[0m(-0.014576077461242676)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1122.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 102/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:50:10) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:50:24 -- STEP: 3/11 -- GLOBAL_STEP: 1125\u001b[0m\n",
            "     | > loss: 0.8186063766479492  (0.8086286981900533)\n",
            "     | > log_mle: 0.1021912693977356  (0.0972713828086853)\n",
            "     | > loss_dur: 0.7164151072502136  (0.711357315381368)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.7551, device='cuda:0')  (tensor(1.9544, device='cuda:0'))\n",
            "     | > current_lr: 2.55e-05 \n",
            "     | > step_time: 1.6947  (2.0609959761301675)\n",
            "     | > loader_time: 0.0166  (0.03555631637573242)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8456268310546875 \u001b[0m(+0.07651329040527344)\n",
            "     | > avg_loss:\u001b[92m 0.7858622670173645 \u001b[0m(-0.015835225582122803)\n",
            "     | > avg_log_mle:\u001b[92m 0.12244576215744019 \u001b[0m(-0.003754913806915283)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6634165048599243 \u001b[0m(-0.01208031177520752)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1133.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 103/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:50:45) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6724624633789062 \u001b[0m(-0.17316436767578125)\n",
            "     | > avg_loss:\u001b[92m 0.7728098034858704 \u001b[0m(-0.01305246353149414)\n",
            "     | > avg_log_mle:\u001b[92m 0.11898893117904663 \u001b[0m(-0.0034568309783935547)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6538208723068237 \u001b[0m(-0.009595632553100586)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1144.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 104/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:51:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:51:48 -- STEP: 6/11 -- GLOBAL_STEP: 1150\u001b[0m\n",
            "     | > loss: 0.8259833455085754  (0.8046289881070455)\n",
            "     | > log_mle: 0.08373421430587769  (0.08808871110280354)\n",
            "     | > loss_dur: 0.7422491312026978  (0.7165402770042419)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.6946, device='cuda:0')  (tensor(2.1863, device='cuda:0'))\n",
            "     | > current_lr: 2.6e-05 \n",
            "     | > step_time: 0.7059  (1.3624505996704102)\n",
            "     | > loader_time: 0.0087  (0.021242817242940266)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8417263031005859 \u001b[0m(+0.1692638397216797)\n",
            "     | > avg_loss:\u001b[92m 0.7633243203163147 \u001b[0m(-0.009485483169555664)\n",
            "     | > avg_log_mle:\u001b[92m 0.11407071352005005 \u001b[0m(-0.004918217658996582)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6492536067962646 \u001b[0m(-0.004567265510559082)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1155.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 105/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:52:10) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6609823703765869 \u001b[0m(-0.18074393272399902)\n",
            "     | > avg_loss:\u001b[92m 0.7578583359718323 \u001b[0m(-0.005465984344482422)\n",
            "     | > avg_log_mle:\u001b[92m 0.10990113019943237 \u001b[0m(-0.004169583320617676)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6479572057723999 \u001b[0m(-0.001296401023864746)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1166.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 106/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:52:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:53:08 -- STEP: 9/11 -- GLOBAL_STEP: 1175\u001b[0m\n",
            "     | > loss: 0.8167539238929749  (0.7957371009720696)\n",
            "     | > log_mle: 0.07917129993438721  (0.07762305604086982)\n",
            "     | > loss_dur: 0.7375826239585876  (0.7181140449311998)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.0254, device='cuda:0')  (tensor(2.2741, device='cuda:0'))\n",
            "     | > current_lr: 2.65e-05 \n",
            "     | > step_time: 0.806  (1.6428762012057834)\n",
            "     | > loader_time: 0.0069  (0.024630599551730685)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6563231945037842 \u001b[0m(-0.004659175872802734)\n",
            "     | > avg_loss:\u001b[92m 0.7436458468437195 \u001b[0m(-0.014212489128112793)\n",
            "     | > avg_log_mle:\u001b[92m 0.1061827540397644 \u001b[0m(-0.0037183761596679688)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6374630928039551 \u001b[0m(-0.010494112968444824)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1177.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 107/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:53:23) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.7955586910247803 \u001b[0m(+1.139235496520996)\n",
            "     | > avg_loss:\u001b[92m 0.735088586807251 \u001b[0m(-0.008557260036468506)\n",
            "     | > avg_log_mle:\u001b[92m 0.10214436054229736 \u001b[0m(-0.004038393497467041)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6329442262649536 \u001b[0m(-0.004518866539001465)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1188.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 108/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:54:08) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 1.0184905529022217 \u001b[0m(-0.7770681381225586)\n",
            "     | > avg_loss:\u001b[92m 0.7256356477737427 \u001b[0m(-0.0094529390335083)\n",
            "     | > avg_log_mle:\u001b[92m 0.09914052486419678 \u001b[0m(-0.003003835678100586)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6264951229095459 \u001b[0m(-0.006449103355407715)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1199.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 109/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:54:42) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:54:54 -- STEP: 1/11 -- GLOBAL_STEP: 1200\u001b[0m\n",
            "     | > loss: 0.7288715839385986  (0.7288715839385986)\n",
            "     | > log_mle: 0.07189935445785522  (0.07189935445785522)\n",
            "     | > loss_dur: 0.6569722294807434  (0.6569722294807434)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.8374, device='cuda:0')  (tensor(1.8374, device='cuda:0'))\n",
            "     | > current_lr: 2.725e-05 \n",
            "     | > step_time: 2.2349  (2.2349114418029785)\n",
            "     | > loader_time: 0.041  (0.0409696102142334)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_1200.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8091795444488525 \u001b[0m(-0.20931100845336914)\n",
            "     | > avg_loss:\u001b[92m 0.7135300636291504 \u001b[0m(-0.012105584144592285)\n",
            "     | > avg_log_mle:\u001b[92m 0.09577286243438721 \u001b[0m(-0.0033676624298095703)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6177572011947632 \u001b[0m(-0.008737921714782715)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1210.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 110/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:55:24) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.700716495513916 \u001b[0m(-0.10846304893493652)\n",
            "     | > avg_loss:\u001b[92m 0.704120934009552 \u001b[0m(-0.009409129619598389)\n",
            "     | > avg_log_mle:\u001b[92m 0.09186404943466187 \u001b[0m(-0.003908812999725342)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6122568845748901 \u001b[0m(-0.005500316619873047)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1221.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 111/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:56:15) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:56:28 -- STEP: 4/11 -- GLOBAL_STEP: 1225\u001b[0m\n",
            "     | > loss: 0.7550226449966431  (0.7269094288349152)\n",
            "     | > log_mle: 0.06311017274856567  (0.06260272860527039)\n",
            "     | > loss_dur: 0.6919124722480774  (0.6643067002296448)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.0270, device='cuda:0')  (tensor(1.8929, device='cuda:0'))\n",
            "     | > current_lr: 2.775e-05 \n",
            "     | > step_time: 2.3839  (1.982937216758728)\n",
            "     | > loader_time: 0.0831  (0.03579205274581909)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6643919944763184 \u001b[0m(-0.036324501037597656)\n",
            "     | > avg_loss:\u001b[91m 0.7077572345733643 \u001b[0m(+0.003636300563812256)\n",
            "     | > avg_log_mle:\u001b[92m 0.08912575244903564 \u001b[0m(-0.0027382969856262207)\n",
            "     | > avg_loss_dur:\u001b[91m 0.6186314821243286 \u001b[0m(+0.0063745975494384766)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 112/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:56:45) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.0130324363708496 \u001b[0m(+0.34864044189453125)\n",
            "     | > avg_loss:\u001b[92m 0.6983014345169067 \u001b[0m(-0.00945580005645752)\n",
            "     | > avg_log_mle:\u001b[92m 0.08482962846755981 \u001b[0m(-0.00429612398147583)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6134718060493469 \u001b[0m(-0.0051596760749816895)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1243.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 113/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:57:21) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:57:38 -- STEP: 7/11 -- GLOBAL_STEP: 1250\u001b[0m\n",
            "     | > loss: 0.737787127494812  (0.7194492646626064)\n",
            "     | > log_mle: 0.04523491859436035  (0.05354588372366769)\n",
            "     | > loss_dur: 0.6925522089004517  (0.6659033809389386)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.9903, device='cuda:0')  (tensor(2.0421, device='cuda:0'))\n",
            "     | > current_lr: 2.8250000000000002e-05 \n",
            "     | > step_time: 0.6446  (1.1878891331808907)\n",
            "     | > loader_time: 0.0111  (0.015789576939174106)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 2.102823495864868 \u001b[0m(+1.0897910594940186)\n",
            "     | > avg_loss:\u001b[92m 0.6833546161651611 \u001b[0m(-0.014946818351745605)\n",
            "     | > avg_log_mle:\u001b[92m 0.0809895396232605 \u001b[0m(-0.0038400888442993164)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6023650765419006 \u001b[0m(-0.011106729507446289)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1254.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 114/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:58:00) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.693962812423706 \u001b[0m(-1.408860683441162)\n",
            "     | > avg_loss:\u001b[92m 0.6798589825630188 \u001b[0m(-0.003495633602142334)\n",
            "     | > avg_log_mle:\u001b[92m 0.07791978120803833 \u001b[0m(-0.003069758415222168)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6019392013549805 \u001b[0m(-0.000425875186920166)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1265.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 115/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:58:44) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 18:59:05 -- STEP: 10/11 -- GLOBAL_STEP: 1275\u001b[0m\n",
            "     | > loss: 0.70700603723526  (0.7069038629531861)\n",
            "     | > log_mle: 0.031188547611236572  (0.044260460138320926)\n",
            "     | > loss_dur: 0.6758174896240234  (0.6626434028148651)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.8186, device='cuda:0')  (tensor(1.8960, device='cuda:0'))\n",
            "     | > current_lr: 2.875e-05 \n",
            "     | > step_time: 0.4506  (1.4147170543670655)\n",
            "     | > loader_time: 0.0051  (0.018130803108215333)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.67081618309021 \u001b[0m(-0.023146629333496094)\n",
            "     | > avg_loss:\u001b[92m 0.6601248979568481 \u001b[0m(-0.019734084606170654)\n",
            "     | > avg_log_mle:\u001b[92m 0.07506752014160156 \u001b[0m(-0.0028522610664367676)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5850573778152466 \u001b[0m(-0.016881823539733887)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1276.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 116/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 18:59:22) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6686148643493652 \u001b[0m(-0.0022013187408447266)\n",
            "     | > avg_loss:\u001b[92m 0.6526046395301819 \u001b[0m(-0.00752025842666626)\n",
            "     | > avg_log_mle:\u001b[92m 0.07178211212158203 \u001b[0m(-0.0032854080200195312)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5808225274085999 \u001b[0m(-0.0042348504066467285)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1287.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 117/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:00:01) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.1694798469543457 \u001b[0m(+0.5008649826049805)\n",
            "     | > avg_loss:\u001b[92m 0.6339230537414551 \u001b[0m(-0.018681585788726807)\n",
            "     | > avg_log_mle:\u001b[92m 0.068825364112854 \u001b[0m(-0.0029567480087280273)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5650976896286011 \u001b[0m(-0.01572483777999878)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1298.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 118/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:00:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:00:58 -- STEP: 2/11 -- GLOBAL_STEP: 1300\u001b[0m\n",
            "     | > loss: 0.6593970656394958  (0.6491215825080872)\n",
            "     | > log_mle: 0.03319859504699707  (0.03741508722305298)\n",
            "     | > loss_dur: 0.6261984705924988  (0.6117064952850342)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.1942, device='cuda:0')  (tensor(3.0247, device='cuda:0'))\n",
            "     | > current_lr: 2.95e-05 \n",
            "     | > step_time: 2.7198  (2.2220425605773926)\n",
            "     | > loader_time: 0.0254  (0.04338371753692627)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 1.0599026679992676 \u001b[0m(-0.10957717895507812)\n",
            "     | > avg_loss:\u001b[92m 0.6328345537185669 \u001b[0m(-0.0010885000228881836)\n",
            "     | > avg_log_mle:\u001b[92m 0.06556826829910278 \u001b[0m(-0.0032570958137512207)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5672662854194641 \u001b[0m(+0.002168595790863037)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1309.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 119/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:01:41) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8137557506561279 \u001b[0m(-0.24614691734313965)\n",
            "     | > avg_loss:\u001b[92m 0.6284841299057007 \u001b[0m(-0.004350423812866211)\n",
            "     | > avg_log_mle:\u001b[92m 0.062035560607910156 \u001b[0m(-0.003532707691192627)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5664485692977905 \u001b[0m(-0.000817716121673584)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1320.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 120/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:02:23) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:02:41 -- STEP: 5/11 -- GLOBAL_STEP: 1325\u001b[0m\n",
            "     | > loss: 0.6769973039627075  (0.65303715467453)\n",
            "     | > log_mle: 0.03403615951538086  (0.033596372604370116)\n",
            "     | > loss_dur: 0.6429611444473267  (0.61944078207016)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.0136, device='cuda:0')  (tensor(2.3322, device='cuda:0'))\n",
            "     | > current_lr: 2.9999999999999997e-05 \n",
            "     | > step_time: 0.6409  (1.783630132675171)\n",
            "     | > loader_time: 0.0086  (0.022824192047119142)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7471046447753906 \u001b[0m(-0.0666511058807373)\n",
            "     | > avg_loss:\u001b[92m 0.627425491809845 \u001b[0m(-0.0010586380958557129)\n",
            "     | > avg_log_mle:\u001b[92m 0.05851691961288452 \u001b[0m(-0.0035186409950256348)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5689085721969604 \u001b[0m(+0.002460002899169922)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1331.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 121/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:03:01) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7678263187408447 \u001b[0m(+0.0207216739654541)\n",
            "     | > avg_loss:\u001b[92m 0.6142866015434265 \u001b[0m(-0.013138890266418457)\n",
            "     | > avg_log_mle:\u001b[92m 0.05601555109024048 \u001b[0m(-0.002501368522644043)\n",
            "     | > avg_loss_dur:\u001b[92m 0.558271050453186 \u001b[0m(-0.010637521743774414)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1342.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 122/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:03:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:04:09 -- STEP: 8/11 -- GLOBAL_STEP: 1350\u001b[0m\n",
            "     | > loss: 0.6631287336349487  (0.6474924236536026)\n",
            "     | > log_mle: 0.01603800058364868  (0.025189079344272614)\n",
            "     | > loss_dur: 0.6470907330513  (0.62230334430933)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.5870, device='cuda:0')  (tensor(2.6343, device='cuda:0'))\n",
            "     | > current_lr: 3.05e-05 \n",
            "     | > step_time: 0.8251  (1.7708432972431183)\n",
            "     | > loader_time: 0.0138  (0.3631073534488678)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6685917377471924 \u001b[0m(-0.09923458099365234)\n",
            "     | > avg_loss:\u001b[92m 0.610908567905426 \u001b[0m(-0.0033780336380004883)\n",
            "     | > avg_log_mle:\u001b[92m 0.05434882640838623 \u001b[0m(-0.001666724681854248)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5565597414970398 \u001b[0m(-0.0017113089561462402)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1353.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 123/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:04:29) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.5978729724884033 \u001b[0m(+0.9292812347412109)\n",
            "     | > avg_loss:\u001b[92m 0.6090072989463806 \u001b[0m(-0.0019012689590454102)\n",
            "     | > avg_log_mle:\u001b[92m 0.05095982551574707 \u001b[0m(-0.00338900089263916)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5580474734306335 \u001b[0m(+0.00148773193359375)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1364.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 124/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:05:13) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6939454078674316 \u001b[0m(-0.9039275646209717)\n",
            "     | > avg_loss:\u001b[92m 0.6005085110664368 \u001b[0m(-0.008498787879943848)\n",
            "     | > avg_log_mle:\u001b[92m 0.04865097999572754 \u001b[0m(-0.0023088455200195312)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5518575310707092 \u001b[0m(-0.006189942359924316)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1375.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 125/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:05:54) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:05:59 -- STEP: 0/11 -- GLOBAL_STEP: 1375\u001b[0m\n",
            "     | > loss: 0.541330099105835  (0.541330099105835)\n",
            "     | > log_mle: 0.012563169002532959  (0.012563169002532959)\n",
            "     | > loss_dur: 0.528766930103302  (0.528766930103302)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.4440, device='cuda:0')  (tensor(1.4440, device='cuda:0'))\n",
            "     | > current_lr: 3.125e-05 \n",
            "     | > step_time: 1.7796  (1.7795891761779785)\n",
            "     | > loader_time: 2.935  (2.934959650039673)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.2094635963439941 \u001b[0m(+0.5155181884765625)\n",
            "     | > avg_loss:\u001b[92m 0.5977176427841187 \u001b[0m(-0.0027908682823181152)\n",
            "     | > avg_log_mle:\u001b[92m 0.04486209154129028 \u001b[0m(-0.003788888454437256)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5528555512428284 \u001b[0m(+0.0009980201721191406)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1386.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 126/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:06:49) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 1.0679748058319092 \u001b[0m(-0.14148879051208496)\n",
            "     | > avg_loss:\u001b[91m 0.6042695045471191 \u001b[0m(+0.006551861763000488)\n",
            "     | > avg_log_mle:\u001b[92m 0.042470693588256836 \u001b[0m(-0.0023913979530334473)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5617988109588623 \u001b[0m(+0.008943259716033936)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 127/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:07:35) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:07:56 -- STEP: 3/11 -- GLOBAL_STEP: 1400\u001b[0m\n",
            "     | > loss: 0.5983147025108337  (0.5852236747741699)\n",
            "     | > log_mle: 0.019616544246673584  (0.01342990001042684)\n",
            "     | > loss_dur: 0.5786981582641602  (0.571793774763743)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.7698, device='cuda:0')  (tensor(1.5609, device='cuda:0'))\n",
            "     | > current_lr: 3.1750000000000006e-05 \n",
            "     | > step_time: 3.1608  (2.3502767086029053)\n",
            "     | > loader_time: 0.0239  (0.018718640009562176)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_1400.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.1407029628753662 \u001b[0m(+0.07272815704345703)\n",
            "     | > avg_loss:\u001b[92m 0.5875545144081116 \u001b[0m(-0.01671499013900757)\n",
            "     | > avg_log_mle:\u001b[92m 0.03906702995300293 \u001b[0m(-0.0034036636352539062)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5484874844551086 \u001b[0m(-0.013311326503753662)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1408.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 128/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:08:42) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6440536975860596 \u001b[0m(-0.49664926528930664)\n",
            "     | > avg_loss:\u001b[92m 0.5807219743728638 \u001b[0m(-0.006832540035247803)\n",
            "     | > avg_log_mle:\u001b[92m 0.036141157150268555 \u001b[0m(-0.002925872802734375)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5445808172225952 \u001b[0m(-0.003906667232513428)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1419.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 129/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:09:36) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:09:59 -- STEP: 6/11 -- GLOBAL_STEP: 1425\u001b[0m\n",
            "     | > loss: 0.5999682545661926  (0.5906631847222646)\n",
            "     | > log_mle: 0.004654407501220703  (0.007792741060256958)\n",
            "     | > loss_dur: 0.5953138470649719  (0.5828704436620077)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.4148, device='cuda:0')  (tensor(1.5513, device='cuda:0'))\n",
            "     | > current_lr: 3.225e-05 \n",
            "     | > step_time: 1.0873  (2.6199199755986533)\n",
            "     | > loader_time: 0.0118  (0.018798669179280598)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.1744105815887451 \u001b[0m(+0.5303568840026855)\n",
            "     | > avg_loss:\u001b[92m 0.5764240622520447 \u001b[0m(-0.004297912120819092)\n",
            "     | > avg_log_mle:\u001b[92m 0.03505736589431763 \u001b[0m(-0.0010837912559509277)\n",
            "     | > avg_loss_dur:\u001b[92m 0.541366696357727 \u001b[0m(-0.003214120864868164)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1430.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 130/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:10:29) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 1.0708982944488525 \u001b[0m(-0.10351228713989258)\n",
            "     | > avg_loss:\u001b[92m 0.5623799562454224 \u001b[0m(-0.014044106006622314)\n",
            "     | > avg_log_mle:\u001b[92m 0.03164100646972656 \u001b[0m(-0.0034163594245910645)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5307389497756958 \u001b[0m(-0.01062774658203125)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1441.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 131/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:11:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:11:49 -- STEP: 9/11 -- GLOBAL_STEP: 1450\u001b[0m\n",
            "     | > loss: 0.608309805393219  (0.5835814873377482)\n",
            "     | > log_mle: 0.002566218376159668  (0.001261644893222385)\n",
            "     | > loss_dur: 0.6057435870170593  (0.5823198424445258)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.7133, device='cuda:0')  (tensor(2.7380, device='cuda:0'))\n",
            "     | > current_lr: 3.2749999999999996e-05 \n",
            "     | > step_time: 1.5681  (1.9661243226793077)\n",
            "     | > loader_time: 0.009  (0.030091709560818143)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.9752819538116455 \u001b[0m(-0.09561634063720703)\n",
            "     | > avg_loss:\u001b[92m 0.5554796457290649 \u001b[0m(-0.006900310516357422)\n",
            "     | > avg_log_mle:\u001b[92m 0.0286637544631958 \u001b[0m(-0.0029772520065307617)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5268158912658691 \u001b[0m(-0.00392305850982666)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1452.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 132/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:12:13) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.167522668838501 \u001b[0m(+0.19224071502685547)\n",
            "     | > avg_loss:\u001b[92m 0.5433153510093689 \u001b[0m(-0.012164294719696045)\n",
            "     | > avg_log_mle:\u001b[92m 0.026418864727020264 \u001b[0m(-0.002244889736175537)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5168964862823486 \u001b[0m(-0.009919404983520508)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1463.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 133/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:13:07) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7236502170562744 \u001b[0m(-0.44387245178222656)\n",
            "     | > avg_loss:\u001b[92m 0.5414994359016418 \u001b[0m(-0.0018159151077270508)\n",
            "     | > avg_log_mle:\u001b[92m 0.02445530891418457 \u001b[0m(-0.0019635558128356934)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5170441269874573 \u001b[0m(+0.00014764070510864258)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1474.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 134/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:13:59) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:14:09 -- STEP: 1/11 -- GLOBAL_STEP: 1475\u001b[0m\n",
            "     | > loss: 0.5152291059494019  (0.5152291059494019)\n",
            "     | > log_mle: -0.0028129220008850098  (-0.0028129220008850098)\n",
            "     | > loss_dur: 0.5180420279502869  (0.5180420279502869)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.3425, device='cuda:0')  (tensor(3.3425, device='cuda:0'))\n",
            "     | > current_lr: 3.35e-05 \n",
            "     | > step_time: 1.8528  (1.852750539779663)\n",
            "     | > loader_time: 0.0145  (0.014462947845458984)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.0008304119110107 \u001b[0m(+0.27718019485473633)\n",
            "     | > avg_loss:\u001b[91m 0.557822048664093 \u001b[0m(+0.016322612762451172)\n",
            "     | > avg_log_mle:\u001b[92m 0.023432612419128418 \u001b[0m(-0.0010226964950561523)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5343894362449646 \u001b[0m(+0.017345309257507324)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 135/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:14:45) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.9840164184570312 \u001b[0m(-0.016813993453979492)\n",
            "     | > avg_loss:\u001b[92m 0.550324559211731 \u001b[0m(-0.0074974894523620605)\n",
            "     | > avg_log_mle:\u001b[92m 0.01977229118347168 \u001b[0m(-0.0036603212356567383)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5305522680282593 \u001b[0m(-0.0038371682167053223)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 136/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:15:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:15:49 -- STEP: 4/11 -- GLOBAL_STEP: 1500\u001b[0m\n",
            "     | > loss: 0.5641034245491028  (0.5405125617980957)\n",
            "     | > log_mle: -0.007136702537536621  (-0.00885896384716034)\n",
            "     | > loss_dur: 0.5712401270866394  (0.549371525645256)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.3639, device='cuda:0')  (tensor(2.0960, device='cuda:0'))\n",
            "     | > current_lr: 3.4e-05 \n",
            "     | > step_time: 2.7189  (3.0964182019233704)\n",
            "     | > loader_time: 0.0473  (0.03403019905090332)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6503250598907471 \u001b[0m(-0.3336913585662842)\n",
            "     | > avg_loss:\u001b[92m 0.5356617569923401 \u001b[0m(-0.01466280221939087)\n",
            "     | > avg_log_mle:\u001b[92m 0.017179489135742188 \u001b[0m(-0.002592802047729492)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5184822678565979 \u001b[0m(-0.012070000171661377)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1507.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 137/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:16:11) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6475920677185059 \u001b[0m(-0.002732992172241211)\n",
            "     | > avg_loss:\u001b[91m 0.5383322238922119 \u001b[0m(+0.002670466899871826)\n",
            "     | > avg_log_mle:\u001b[92m 0.014614582061767578 \u001b[0m(-0.0025649070739746094)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5237176418304443 \u001b[0m(+0.0052353739738464355)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 138/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:16:49) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:17:05 -- STEP: 7/11 -- GLOBAL_STEP: 1525\u001b[0m\n",
            "     | > loss: 0.5566187500953674  (0.5426897321428571)\n",
            "     | > log_mle: -0.02106499671936035  (-0.015178697449820382)\n",
            "     | > loss_dur: 0.5776837468147278  (0.5578684295926776)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.3001, device='cuda:0')  (tensor(1.8562, device='cuda:0'))\n",
            "     | > current_lr: 3.45e-05 \n",
            "     | > step_time: 0.7516  (1.641019003731864)\n",
            "     | > loader_time: 0.009  (0.028104986463274275)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6765639781951904 \u001b[0m(+0.02897191047668457)\n",
            "     | > avg_loss:\u001b[92m 0.522946834564209 \u001b[0m(-0.01538538932800293)\n",
            "     | > avg_log_mle:\u001b[92m 0.012611329555511475 \u001b[0m(-0.0020032525062561035)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5103355050086975 \u001b[0m(-0.013382136821746826)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1529.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 139/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:17:25) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv1d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6619493961334229 \u001b[0m(-0.014614582061767578)\n",
            "     | > avg_loss:\u001b[91m 0.5304067134857178 \u001b[0m(+0.007459878921508789)\n",
            "     | > avg_log_mle:\u001b[92m 0.00928199291229248 \u001b[0m(-0.003329336643218994)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5211247205734253 \u001b[0m(+0.010789215564727783)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 140/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:18:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:18:22 -- STEP: 10/11 -- GLOBAL_STEP: 1550\u001b[0m\n",
            "     | > loss: 0.54538494348526  (0.5348735988140106)\n",
            "     | > log_mle: -0.03552830219268799  (-0.02237420082092285)\n",
            "     | > loss_dur: 0.580913245677948  (0.5572477996349334)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.9802, device='cuda:0')  (tensor(1.6507, device='cuda:0'))\n",
            "     | > current_lr: 3.5000000000000004e-05 \n",
            "     | > step_time: 0.4227  (1.5060607194900513)\n",
            "     | > loader_time: 0.0048  (0.017676568031311034)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6669104099273682 \u001b[0m(+0.0049610137939453125)\n",
            "     | > avg_loss:\u001b[91m 0.5306447744369507 \u001b[0m(+0.00023806095123291016)\n",
            "     | > avg_log_mle:\u001b[92m 0.007513701915740967 \u001b[0m(-0.0017682909965515137)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5231310725212097 \u001b[0m(+0.002006351947784424)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 141/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:18:36) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6460325717926025 \u001b[0m(-0.020877838134765625)\n",
            "     | > avg_loss:\u001b[91m 0.5327159762382507 \u001b[0m(+0.002071201801300049)\n",
            "     | > avg_log_mle:\u001b[92m 0.006686508655548096 \u001b[0m(-0.0008271932601928711)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5260294675827026 \u001b[0m(+0.00289839506149292)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 142/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:19:08) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6618437767028809 \u001b[0m(+0.01581120491027832)\n",
            "     | > avg_loss:\u001b[92m 0.5283494591712952 \u001b[0m(-0.004366517066955566)\n",
            "     | > avg_log_mle:\u001b[92m 0.002146422863006592 \u001b[0m(-0.004540085792541504)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5262030363082886 \u001b[0m(+0.0001735687255859375)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 143/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:19:39) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:19:47 -- STEP: 2/11 -- GLOBAL_STEP: 1575\u001b[0m\n",
            "     | > loss: 0.5090404748916626  (0.488323450088501)\n",
            "     | > log_mle: -0.031916916370391846  (-0.028576135635375977)\n",
            "     | > loss_dur: 0.5409573912620544  (0.516899585723877)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.5899, device='cuda:0')  (tensor(2.2547, device='cuda:0'))\n",
            "     | > current_lr: 3.575e-05 \n",
            "     | > step_time: 1.7575  (1.8226139545440674)\n",
            "     | > loader_time: 0.0308  (0.02169942855834961)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6499061584472656 \u001b[0m(-0.011937618255615234)\n",
            "     | > avg_loss:\u001b[92m 0.5183373093605042 \u001b[0m(-0.010012149810791016)\n",
            "     | > avg_log_mle:\u001b[92m 0.0005778670310974121 \u001b[0m(-0.0015685558319091797)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5177594423294067 \u001b[0m(-0.008443593978881836)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1584.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 144/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:20:13) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6481904983520508 \u001b[0m(-0.0017156600952148438)\n",
            "     | > avg_loss:\u001b[91m 0.5217368602752686 \u001b[0m(+0.0033995509147644043)\n",
            "     | > avg_log_mle:\u001b[92m -0.0011768937110900879 \u001b[0m(-0.0017547607421875)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5229137539863586 \u001b[0m(+0.005154311656951904)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 145/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:20:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:21:04 -- STEP: 5/11 -- GLOBAL_STEP: 1600\u001b[0m\n",
            "     | > loss: 0.5166961550712585  (0.4999313950538635)\n",
            "     | > log_mle: -0.02772068977355957  (-0.02944900989532471)\n",
            "     | > loss_dur: 0.5444168448448181  (0.5293804049491883)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.5533, device='cuda:0')  (tensor(1.6938, device='cuda:0'))\n",
            "     | > current_lr: 3.625e-05 \n",
            "     | > step_time: 0.9327  (1.7488272666931153)\n",
            "     | > loader_time: 0.0129  (0.02073845863342285)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_1600.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6447622776031494 \u001b[0m(-0.003428220748901367)\n",
            "     | > avg_loss:\u001b[92m 0.5134774446487427 \u001b[0m(-0.008259415626525879)\n",
            "     | > avg_log_mle:\u001b[92m -0.003543078899383545 \u001b[0m(-0.002366185188293457)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5170205235481262 \u001b[0m(-0.005893230438232422)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1606.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 146/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:21:36) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6637842655181885 \u001b[0m(+0.019021987915039062)\n",
            "     | > avg_loss:\u001b[91m 0.5141946077346802 \u001b[0m(+0.0007171630859375)\n",
            "     | > avg_log_mle:\u001b[92m -0.004874706268310547 \u001b[0m(-0.001331627368927002)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5190693140029907 \u001b[0m(+0.002048790454864502)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 147/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:22:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:22:28 -- STEP: 8/11 -- GLOBAL_STEP: 1625\u001b[0m\n",
            "     | > loss: 0.5167446136474609  (0.49495286867022514)\n",
            "     | > log_mle: -0.04388129711151123  (-0.03618372976779938)\n",
            "     | > loss_dur: 0.5606259107589722  (0.5311365984380245)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.3921, device='cuda:0')  (tensor(1.5617, device='cuda:0'))\n",
            "     | > current_lr: 3.675e-05 \n",
            "     | > step_time: 0.832  (1.2208585739135742)\n",
            "     | > loader_time: 0.0082  (0.018871694803237915)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6607155799865723 \u001b[0m(-0.003068685531616211)\n",
            "     | > avg_loss:\u001b[92m 0.5027523040771484 \u001b[0m(-0.011442303657531738)\n",
            "     | > avg_log_mle:\u001b[92m -0.007738471031188965 \u001b[0m(-0.002863764762878418)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5104907751083374 \u001b[0m(-0.00857853889465332)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1628.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 148/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:22:47) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.642021894454956 \u001b[0m(-0.01869368553161621)\n",
            "     | > avg_loss:\u001b[91m 0.5071487426757812 \u001b[0m(+0.0043964385986328125)\n",
            "     | > avg_log_mle:\u001b[92m -0.010695695877075195 \u001b[0m(-0.0029572248458862305)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5178444385528564 \u001b[0m(+0.007353663444519043)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 149/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:23:24) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6799297332763672 \u001b[0m(+0.03790783882141113)\n",
            "     | > avg_loss:\u001b[92m 0.4911690950393677 \u001b[0m(-0.015979647636413574)\n",
            "     | > avg_log_mle:\u001b[92m -0.01253432035446167 \u001b[0m(-0.0018386244773864746)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5037034153938293 \u001b[0m(-0.0141410231590271)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1650.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 150/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:24:04) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:24:09 -- STEP: 0/11 -- GLOBAL_STEP: 1650\u001b[0m\n",
            "     | > loss: 0.40766412019729614  (0.40766412019729614)\n",
            "     | > log_mle: -0.04897427558898926  (-0.04897427558898926)\n",
            "     | > loss_dur: 0.4566383957862854  (0.4566383957862854)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.4209, device='cuda:0')  (tensor(1.4209, device='cuda:0'))\n",
            "     | > current_lr: 3.75e-05 \n",
            "     | > step_time: 2.043  (2.0429844856262207)\n",
            "     | > loader_time: 2.8986  (2.8986117839813232)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6487386226654053 \u001b[0m(-0.031191110610961914)\n",
            "     | > avg_loss:\u001b[91m 0.49190449714660645 \u001b[0m(+0.0007354021072387695)\n",
            "     | > avg_log_mle:\u001b[92m -0.014768123626708984 \u001b[0m(-0.0022338032722473145)\n",
            "     | > avg_loss_dur:\u001b[91m 0.5066726207733154 \u001b[0m(+0.002969205379486084)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 151/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:24:41) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6691625118255615 \u001b[0m(+0.02042388916015625)\n",
            "     | > avg_loss:\u001b[92m 0.4840241074562073 \u001b[0m(-0.00788038969039917)\n",
            "     | > avg_log_mle:\u001b[92m -0.016179025173187256 \u001b[0m(-0.0014109015464782715)\n",
            "     | > avg_loss_dur:\u001b[92m 0.5002031326293945 \u001b[0m(-0.0064694881439208984)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1672.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 152/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:25:21) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:25:40 -- STEP: 3/11 -- GLOBAL_STEP: 1675\u001b[0m\n",
            "     | > loss: 0.4638238549232483  (0.447821984688441)\n",
            "     | > log_mle: -0.03917038440704346  (-0.04551233847935995)\n",
            "     | > loss_dur: 0.5029942393302917  (0.4933343231678009)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.1151, device='cuda:0')  (tensor(2.0711, device='cuda:0'))\n",
            "     | > current_lr: 3.7999999999999995e-05 \n",
            "     | > step_time: 2.6362  (2.0565241972605386)\n",
            "     | > loader_time: 0.0193  (0.018384218215942383)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.5652201175689697 \u001b[0m(+0.8960576057434082)\n",
            "     | > avg_loss:\u001b[92m 0.47368234395980835 \u001b[0m(-0.010341763496398926)\n",
            "     | > avg_log_mle:\u001b[92m -0.019410431385040283 \u001b[0m(-0.0032314062118530273)\n",
            "     | > avg_loss_dur:\u001b[92m 0.49309277534484863 \u001b[0m(-0.0071103572845458984)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1683.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 153/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:26:08) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6563253402709961 \u001b[0m(-0.9088947772979736)\n",
            "     | > avg_loss:\u001b[92m 0.4713774621486664 \u001b[0m(-0.0023048818111419678)\n",
            "     | > avg_log_mle:\u001b[92m -0.020035386085510254 \u001b[0m(-0.0006249547004699707)\n",
            "     | > avg_loss_dur:\u001b[92m 0.49141284823417664 \u001b[0m(-0.001679927110671997)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1694.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 154/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:26:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:27:08 -- STEP: 6/11 -- GLOBAL_STEP: 1700\u001b[0m\n",
            "     | > loss: 0.4575292468070984  (0.4485683739185333)\n",
            "     | > log_mle: -0.050498902797698975  (-0.048933704694112144)\n",
            "     | > loss_dur: 0.5080281496047974  (0.49750207861264545)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.9671, device='cuda:0')  (tensor(1.8545, device='cuda:0'))\n",
            "     | > current_lr: 3.85e-05 \n",
            "     | > step_time: 0.6648  (2.206877072652181)\n",
            "     | > loader_time: 0.0061  (0.03715113798777262)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.636995792388916 \u001b[0m(-0.019329547882080078)\n",
            "     | > avg_loss:\u001b[92m 0.4652032256126404 \u001b[0m(-0.006174236536026001)\n",
            "     | > avg_log_mle:\u001b[92m -0.021138131618499756 \u001b[0m(-0.001102745532989502)\n",
            "     | > avg_loss_dur:\u001b[92m 0.48634135723114014 \u001b[0m(-0.005071491003036499)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1705.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 155/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:27:28) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.503995418548584 \u001b[0m(+0.866999626159668)\n",
            "     | > avg_loss:\u001b[92m 0.45146864652633667 \u001b[0m(-0.013734579086303711)\n",
            "     | > avg_log_mle:\u001b[92m -0.0237424373626709 \u001b[0m(-0.0026043057441711426)\n",
            "     | > avg_loss_dur:\u001b[92m 0.47521108388900757 \u001b[0m(-0.011130273342132568)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1716.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 156/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:28:15) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:28:38 -- STEP: 9/11 -- GLOBAL_STEP: 1725\u001b[0m\n",
            "     | > loss: 0.4776157736778259  (0.44997314943207634)\n",
            "     | > log_mle: -0.049976468086242676  (-0.05211637417475382)\n",
            "     | > loss_dur: 0.5275922417640686  (0.5020895236068301)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.1431, device='cuda:0')  (tensor(3.2958, device='cuda:0'))\n",
            "     | > current_lr: 3.9e-05 \n",
            "     | > step_time: 0.8114  (1.9234415690104167)\n",
            "     | > loader_time: 0.0075  (0.023906045489841037)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.9644870758056641 \u001b[0m(-0.5395083427429199)\n",
            "     | > avg_loss:\u001b[92m 0.44224947690963745 \u001b[0m(-0.009219169616699219)\n",
            "     | > avg_log_mle:\u001b[92m -0.026745736598968506 \u001b[0m(-0.0030032992362976074)\n",
            "     | > avg_loss_dur:\u001b[92m 0.46899521350860596 \u001b[0m(-0.006215870380401611)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1727.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 157/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:28:57) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.1289007663726807 \u001b[0m(+0.1644136905670166)\n",
            "     | > avg_loss:\u001b[91m 0.45041632652282715 \u001b[0m(+0.008166849613189697)\n",
            "     | > avg_log_mle:\u001b[92m -0.028707802295684814 \u001b[0m(-0.0019620656967163086)\n",
            "     | > avg_loss_dur:\u001b[91m 0.47912412881851196 \u001b[0m(+0.010128915309906006)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 158/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:29:35) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6396355628967285 \u001b[0m(-0.48926520347595215)\n",
            "     | > avg_loss:\u001b[92m 0.44145673513412476 \u001b[0m(-0.008959591388702393)\n",
            "     | > avg_log_mle:\u001b[92m -0.02896296977996826 \u001b[0m(-0.00025516748428344727)\n",
            "     | > avg_loss_dur:\u001b[92m 0.470419704914093 \u001b[0m(-0.008704423904418945)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1749.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 159/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:30:14) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:30:25 -- STEP: 1/11 -- GLOBAL_STEP: 1750\u001b[0m\n",
            "     | > loss: 0.37887662649154663  (0.37887662649154663)\n",
            "     | > log_mle: -0.05941873788833618  (-0.05941873788833618)\n",
            "     | > loss_dur: 0.4382953643798828  (0.4382953643798828)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.0109, device='cuda:0')  (tensor(2.0109, device='cuda:0'))\n",
            "     | > current_lr: 3.9750000000000004e-05 \n",
            "     | > step_time: 3.0199  (3.0198707580566406)\n",
            "     | > loader_time: 0.0456  (0.04559588432312012)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6630828380584717 \u001b[0m(+0.023447275161743164)\n",
            "     | > avg_loss:\u001b[91m 0.442109078168869 \u001b[0m(+0.0006523430347442627)\n",
            "     | > avg_log_mle:\u001b[92m -0.03191262483596802 \u001b[0m(-0.002949655055999756)\n",
            "     | > avg_loss_dur:\u001b[91m 0.47402170300483704 \u001b[0m(+0.0036019980907440186)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 160/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:30:50) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.676814079284668 \u001b[0m(+0.013731241226196289)\n",
            "     | > avg_loss:\u001b[91m 0.4451711177825928 \u001b[0m(+0.003062039613723755)\n",
            "     | > avg_log_mle:\u001b[92m -0.03347623348236084 \u001b[0m(-0.0015636086463928223)\n",
            "     | > avg_loss_dur:\u001b[91m 0.4786473512649536 \u001b[0m(+0.004625648260116577)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 161/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:31:27) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:31:44 -- STEP: 4/11 -- GLOBAL_STEP: 1775\u001b[0m\n",
            "     | > loss: 0.42424750328063965  (0.4012593552470207)\n",
            "     | > log_mle: -0.06025451421737671  (-0.06241869926452637)\n",
            "     | > loss_dur: 0.48450201749801636  (0.4636780545115471)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.6629, device='cuda:0')  (tensor(2.2838, device='cuda:0'))\n",
            "     | > current_lr: 4.025e-05 \n",
            "     | > step_time: 1.7544  (2.6678552627563477)\n",
            "     | > loader_time: 0.0451  (0.04204905033111572)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6522009372711182 \u001b[0m(-0.024613142013549805)\n",
            "     | > avg_loss:\u001b[92m 0.4382064938545227 \u001b[0m(-0.006964623928070068)\n",
            "     | > avg_log_mle:\u001b[92m -0.036517202854156494 \u001b[0m(-0.0030409693717956543)\n",
            "     | > avg_loss_dur:\u001b[92m 0.4747236967086792 \u001b[0m(-0.003923654556274414)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1782.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 162/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:32:10) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.9692466259002686 \u001b[0m(+0.3170456886291504)\n",
            "     | > avg_loss:\u001b[92m 0.42299652099609375 \u001b[0m(-0.015209972858428955)\n",
            "     | > avg_log_mle:\u001b[92m -0.03708392381668091 \u001b[0m(-0.0005667209625244141)\n",
            "     | > avg_loss_dur:\u001b[92m 0.46008044481277466 \u001b[0m(-0.014643251895904541)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1793.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 163/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:32:47) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:33:03 -- STEP: 7/11 -- GLOBAL_STEP: 1800\u001b[0m\n",
            "     | > loss: 0.4214029014110565  (0.4032449424266815)\n",
            "     | > log_mle: -0.07004261016845703  (-0.06610112530844552)\n",
            "     | > loss_dur: 0.49144551157951355  (0.46934606773512705)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.3397, device='cuda:0')  (tensor(2.9059, device='cuda:0'))\n",
            "     | > current_lr: 4.075e-05 \n",
            "     | > step_time: 0.8078  (1.486072301864624)\n",
            "     | > loader_time: 0.0085  (0.018558808735438755)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_1800.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6619341373443604 \u001b[0m(-0.3073124885559082)\n",
            "     | > avg_loss:\u001b[92m 0.41969621181488037 \u001b[0m(-0.003300309181213379)\n",
            "     | > avg_log_mle:\u001b[92m -0.03995990753173828 \u001b[0m(-0.002875983715057373)\n",
            "     | > avg_loss_dur:\u001b[92m 0.45965611934661865 \u001b[0m(-0.00042432546615600586)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1804.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 164/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:33:31) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8895227909088135 \u001b[0m(+0.22758865356445312)\n",
            "     | > avg_loss:\u001b[92m 0.412661075592041 \u001b[0m(-0.0070351362228393555)\n",
            "     | > avg_log_mle:\u001b[92m -0.04171895980834961 \u001b[0m(-0.0017590522766113281)\n",
            "     | > avg_loss_dur:\u001b[92m 0.4543800354003906 \u001b[0m(-0.005276083946228027)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1815.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 165/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:34:18) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:34:38 -- STEP: 10/11 -- GLOBAL_STEP: 1825\u001b[0m\n",
            "     | > loss: 0.3796745240688324  (0.3954853802919388)\n",
            "     | > log_mle: -0.08758258819580078  (-0.07238997220993042)\n",
            "     | > loss_dur: 0.4672571122646332  (0.4678753525018692)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.2582, device='cuda:0')  (tensor(2.3404, device='cuda:0'))\n",
            "     | > current_lr: 4.125e-05 \n",
            "     | > step_time: 0.4079  (1.4298463821411134)\n",
            "     | > loader_time: 0.0053  (0.023403072357177736)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.664968729019165 \u001b[0m(-0.22455406188964844)\n",
            "     | > avg_loss:\u001b[92m 0.40496256947517395 \u001b[0m(-0.007698506116867065)\n",
            "     | > avg_log_mle:\u001b[92m -0.04285025596618652 \u001b[0m(-0.001131296157836914)\n",
            "     | > avg_loss_dur:\u001b[92m 0.4478128254413605 \u001b[0m(-0.006567209959030151)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1826.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 166/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:34:56) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6442334651947021 \u001b[0m(-0.02073526382446289)\n",
            "     | > avg_loss:\u001b[91m 0.40634027123451233 \u001b[0m(+0.001377701759338379)\n",
            "     | > avg_log_mle:\u001b[92m -0.04407680034637451 \u001b[0m(-0.0012265443801879883)\n",
            "     | > avg_loss_dur:\u001b[91m 0.45041707158088684 \u001b[0m(+0.002604246139526367)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 167/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:35:33) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6437389850616455 \u001b[0m(-0.0004944801330566406)\n",
            "     | > avg_loss:\u001b[92m 0.39706552028656006 \u001b[0m(-0.00927475094795227)\n",
            "     | > avg_log_mle:\u001b[92m -0.04603523015975952 \u001b[0m(-0.0019584298133850098)\n",
            "     | > avg_loss_dur:\u001b[92m 0.4431007504463196 \u001b[0m(-0.007316321134567261)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1848.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 168/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:36:14) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:36:28 -- STEP: 2/11 -- GLOBAL_STEP: 1850\u001b[0m\n",
            "     | > loss: 0.3685460686683655  (0.35555051267147064)\n",
            "     | > log_mle: -0.08224058151245117  (-0.07913577556610107)\n",
            "     | > loss_dur: 0.45078665018081665  (0.4346862882375717)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.0378, device='cuda:0')  (tensor(2.6529, device='cuda:0'))\n",
            "     | > current_lr: 4.2e-05 \n",
            "     | > step_time: 2.0567  (2.292895793914795)\n",
            "     | > loader_time: 0.0637  (0.0560147762298584)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.0093414783477783 \u001b[0m(+0.3656024932861328)\n",
            "     | > avg_loss:\u001b[92m 0.39691048860549927 \u001b[0m(-0.00015503168106079102)\n",
            "     | > avg_log_mle:\u001b[92m -0.04794585704803467 \u001b[0m(-0.0019106268882751465)\n",
            "     | > avg_loss_dur:\u001b[91m 0.44485634565353394 \u001b[0m(+0.0017555952072143555)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1859.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 169/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:36:57) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6706459522247314 \u001b[0m(-0.3386955261230469)\n",
            "     | > avg_loss:\u001b[92m 0.38994401693344116 \u001b[0m(-0.0069664716720581055)\n",
            "     | > avg_log_mle:\u001b[92m -0.04900336265563965 \u001b[0m(-0.0010575056076049805)\n",
            "     | > avg_loss_dur:\u001b[92m 0.4389473795890808 \u001b[0m(-0.005908966064453125)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1870.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 170/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:37:36) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:37:56 -- STEP: 5/11 -- GLOBAL_STEP: 1875\u001b[0m\n",
            "     | > loss: 0.3827960193157196  (0.36148805618286134)\n",
            "     | > log_mle: -0.07523620128631592  (-0.07777637243270874)\n",
            "     | > loss_dur: 0.4580322206020355  (0.4392644286155701)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.8442, device='cuda:0')  (tensor(2.7977, device='cuda:0'))\n",
            "     | > current_lr: 4.25e-05 \n",
            "     | > step_time: 2.2975  (2.8286357879638673)\n",
            "     | > loader_time: 0.0204  (0.04105973243713379)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6443452835083008 \u001b[0m(-0.026300668716430664)\n",
            "     | > avg_loss:\u001b[92m 0.38562750816345215 \u001b[0m(-0.004316508769989014)\n",
            "     | > avg_log_mle:\u001b[92m -0.05154699087142944 \u001b[0m(-0.002543628215789795)\n",
            "     | > avg_loss_dur:\u001b[92m 0.4371744990348816 \u001b[0m(-0.0017728805541992188)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1881.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 171/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:38:21) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.587040901184082 \u001b[0m(+0.9426956176757812)\n",
            "     | > avg_loss:\u001b[91m 0.3890955448150635 \u001b[0m(+0.003468036651611328)\n",
            "     | > avg_log_mle:\u001b[92m -0.053869664669036865 \u001b[0m(-0.002322673797607422)\n",
            "     | > avg_loss_dur:\u001b[91m 0.44296520948410034 \u001b[0m(+0.00579071044921875)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 172/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:39:04) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:39:23 -- STEP: 8/11 -- GLOBAL_STEP: 1900\u001b[0m\n",
            "     | > loss: 0.3781664967536926  (0.35993343591690063)\n",
            "     | > log_mle: -0.08975660800933838  (-0.08332826942205429)\n",
            "     | > loss_dur: 0.467923104763031  (0.4432617053389549)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.4263, device='cuda:0')  (tensor(2.6583, device='cuda:0'))\n",
            "     | > current_lr: 4.3e-05 \n",
            "     | > step_time: 0.7037  (1.8191063404083252)\n",
            "     | > loader_time: 0.0079  (0.027700483798980713)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6658504009246826 \u001b[0m(-0.9211905002593994)\n",
            "     | > avg_loss:\u001b[92m 0.37788817286491394 \u001b[0m(-0.011207371950149536)\n",
            "     | > avg_log_mle:\u001b[92m -0.054938435554504395 \u001b[0m(-0.0010687708854675293)\n",
            "     | > avg_loss_dur:\u001b[92m 0.43282660841941833 \u001b[0m(-0.010138601064682007)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1903.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 173/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:39:46) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.9790310859680176 \u001b[0m(+0.31318068504333496)\n",
            "     | > avg_loss:\u001b[92m 0.37247005105018616 \u001b[0m(-0.005418121814727783)\n",
            "     | > avg_log_mle:\u001b[91m -0.05489480495452881 \u001b[0m(+4.363059997558594e-05)\n",
            "     | > avg_loss_dur:\u001b[92m 0.42736485600471497 \u001b[0m(-0.005461752414703369)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1914.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 174/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:40:28) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6728372573852539 \u001b[0m(-0.30619382858276367)\n",
            "     | > avg_loss:\u001b[92m 0.3575661778450012 \u001b[0m(-0.014903873205184937)\n",
            "     | > avg_log_mle:\u001b[92m -0.05900311470031738 \u001b[0m(-0.004108309745788574)\n",
            "     | > avg_loss_dur:\u001b[92m 0.4165692925453186 \u001b[0m(-0.010795563459396362)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1925.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 175/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:41:10) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:41:18 -- STEP: 0/11 -- GLOBAL_STEP: 1925\u001b[0m\n",
            "     | > loss: 0.2725612223148346  (0.2725612223148346)\n",
            "     | > log_mle: -0.09795200824737549  (-0.09795200824737549)\n",
            "     | > loss_dur: 0.3705132305622101  (0.3705132305622101)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(1.4276, device='cuda:0')  (tensor(1.4276, device='cuda:0'))\n",
            "     | > current_lr: 4.375e-05 \n",
            "     | > step_time: 3.1957  (3.19569993019104)\n",
            "     | > loader_time: 4.2356  (4.235562324523926)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.671576976776123 \u001b[0m(-0.0012602806091308594)\n",
            "     | > avg_loss:\u001b[92m 0.3499894440174103 \u001b[0m(-0.007576733827590942)\n",
            "     | > avg_log_mle:\u001b[92m -0.0594448447227478 \u001b[0m(-0.0004417300224304199)\n",
            "     | > avg_loss_dur:\u001b[92m 0.4094342887401581 \u001b[0m(-0.0071350038051605225)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1936.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 176/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:41:53) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.685067892074585 \u001b[0m(+0.013490915298461914)\n",
            "     | > avg_loss:\u001b[92m 0.3397049605846405 \u001b[0m(-0.010284483432769775)\n",
            "     | > avg_log_mle:\u001b[92m -0.061140596866607666 \u001b[0m(-0.0016957521438598633)\n",
            "     | > avg_loss_dur:\u001b[92m 0.40084555745124817 \u001b[0m(-0.008588731288909912)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1947.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 177/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:42:30) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:42:44 -- STEP: 3/11 -- GLOBAL_STEP: 1950\u001b[0m\n",
            "     | > loss: 0.3188001215457916  (0.3125464618206024)\n",
            "     | > log_mle: -0.08590412139892578  (-0.09209807713826497)\n",
            "     | > loss_dur: 0.4047042429447174  (0.4046445389588674)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.5792, device='cuda:0')  (tensor(2.3959, device='cuda:0'))\n",
            "     | > current_lr: 4.425e-05 \n",
            "     | > step_time: 2.6533  (2.7273510297139487)\n",
            "     | > loader_time: 0.0478  (0.034873247146606445)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6652786731719971 \u001b[0m(-0.01978921890258789)\n",
            "     | > avg_loss:\u001b[92m 0.3311755955219269 \u001b[0m(-0.008529365062713623)\n",
            "     | > avg_log_mle:\u001b[92m -0.06319594383239746 \u001b[0m(-0.002055346965789795)\n",
            "     | > avg_loss_dur:\u001b[92m 0.39437153935432434 \u001b[0m(-0.006474018096923828)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1958.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 178/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:43:15) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.0726373195648193 \u001b[0m(+0.40735864639282227)\n",
            "     | > avg_loss:\u001b[92m 0.32867980003356934 \u001b[0m(-0.002495795488357544)\n",
            "     | > avg_log_mle:\u001b[92m -0.06467252969741821 \u001b[0m(-0.001476585865020752)\n",
            "     | > avg_loss_dur:\u001b[92m 0.39335232973098755 \u001b[0m(-0.001019209623336792)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1969.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 179/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:44:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:44:16 -- STEP: 6/11 -- GLOBAL_STEP: 1975\u001b[0m\n",
            "     | > loss: 0.32616162300109863  (0.31809837619463605)\n",
            "     | > log_mle: -0.09228503704071045  (-0.0931447943051656)\n",
            "     | > loss_dur: 0.4184466600418091  (0.41124317049980164)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.9879, device='cuda:0')  (tensor(2.3647, device='cuda:0'))\n",
            "     | > current_lr: 4.475e-05 \n",
            "     | > step_time: 0.7205  (1.9000833829243977)\n",
            "     | > loader_time: 0.0082  (0.026748100916544598)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6564188003540039 \u001b[0m(-0.41621851921081543)\n",
            "     | > avg_loss:\u001b[92m 0.3279880881309509 \u001b[0m(-0.0006917119026184082)\n",
            "     | > avg_log_mle:\u001b[92m -0.06543809175491333 \u001b[0m(-0.0007655620574951172)\n",
            "     | > avg_loss_dur:\u001b[91m 0.39342617988586426 \u001b[0m(+7.385015487670898e-05)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1980.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 180/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:44:37) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6506373882293701 \u001b[0m(-0.005781412124633789)\n",
            "     | > avg_loss:\u001b[92m 0.31528976559638977 \u001b[0m(-0.012698322534561157)\n",
            "     | > avg_log_mle:\u001b[92m -0.06719088554382324 \u001b[0m(-0.0017527937889099121)\n",
            "     | > avg_loss_dur:\u001b[92m 0.382480651140213 \u001b[0m(-0.010945528745651245)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_1991.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 181/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:45:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:45:38 -- STEP: 9/11 -- GLOBAL_STEP: 2000\u001b[0m\n",
            "     | > loss: 0.33438700437545776  (0.3167067931758033)\n",
            "     | > log_mle: -0.09408354759216309  (-0.09685587882995605)\n",
            "     | > loss_dur: 0.42847055196762085  (0.41356267200575936)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.3661, device='cuda:0')  (tensor(2.7499, device='cuda:0'))\n",
            "     | > current_lr: 4.5249999999999995e-05 \n",
            "     | > step_time: 0.7981  (1.5272395875718858)\n",
            "     | > loader_time: 0.0109  (0.022379477818806965)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_2000.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6644318103790283 \u001b[0m(+0.013794422149658203)\n",
            "     | > avg_loss:\u001b[92m 0.30868110060691833 \u001b[0m(-0.0066086649894714355)\n",
            "     | > avg_log_mle:\u001b[92m -0.0704268217086792 \u001b[0m(-0.003235936164855957)\n",
            "     | > avg_loss_dur:\u001b[92m 0.37910792231559753 \u001b[0m(-0.0033727288246154785)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2002.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 182/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:46:07) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6782350540161133 \u001b[0m(+0.013803243637084961)\n",
            "     | > avg_loss:\u001b[91m 0.32128649950027466 \u001b[0m(+0.012605398893356323)\n",
            "     | > avg_log_mle:\u001b[92m -0.0706830620765686 \u001b[0m(-0.0002562403678894043)\n",
            "     | > avg_loss_dur:\u001b[91m 0.39196956157684326 \u001b[0m(+0.012861639261245728)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 183/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:46:46) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7249078750610352 \u001b[0m(+0.046672821044921875)\n",
            "     | > avg_loss:\u001b[92m 0.3201156258583069 \u001b[0m(-0.0011708736419677734)\n",
            "     | > avg_log_mle:\u001b[92m -0.07217109203338623 \u001b[0m(-0.001488029956817627)\n",
            "     | > avg_loss_dur:\u001b[91m 0.3922867178916931 \u001b[0m(+0.0003171563148498535)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 184/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:47:22) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:47:33 -- STEP: 1/11 -- GLOBAL_STEP: 2025\u001b[0m\n",
            "     | > loss: 0.2619522511959076  (0.2619522511959076)\n",
            "     | > log_mle: -0.10391366481781006  (-0.10391366481781006)\n",
            "     | > loss_dur: 0.36586591601371765  (0.36586591601371765)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(2.0330, device='cuda:0')  (tensor(2.0330, device='cuda:0'))\n",
            "     | > current_lr: 4.6e-05 \n",
            "     | > step_time: 2.3128  (2.312838315963745)\n",
            "     | > loader_time: 0.0131  (0.013141155242919922)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.673215389251709 \u001b[0m(-0.05169248580932617)\n",
            "     | > avg_loss:\u001b[92m 0.30837178230285645 \u001b[0m(-0.01174384355545044)\n",
            "     | > avg_log_mle:\u001b[92m -0.07395267486572266 \u001b[0m(-0.0017815828323364258)\n",
            "     | > avg_loss_dur:\u001b[92m 0.3823244571685791 \u001b[0m(-0.009962260723114014)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2035.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 185/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:48:06) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6476800441741943 \u001b[0m(-0.02553534507751465)\n",
            "     | > avg_loss:\u001b[91m 0.30917394161224365 \u001b[0m(+0.000802159309387207)\n",
            "     | > avg_log_mle:\u001b[92m -0.07483786344528198 \u001b[0m(-0.0008851885795593262)\n",
            "     | > avg_loss_dur:\u001b[91m 0.38401180505752563 \u001b[0m(+0.0016873478889465332)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 186/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:48:38) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:48:49 -- STEP: 4/11 -- GLOBAL_STEP: 2050\u001b[0m\n",
            "     | > loss: 0.29400354623794556  (0.27540920674800873)\n",
            "     | > log_mle: -0.10281717777252197  (-0.10580706596374512)\n",
            "     | > loss_dur: 0.39682072401046753  (0.38121627271175385)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(1.9253, device='cuda:0')  (tensor(2.2233, device='cuda:0'))\n",
            "     | > current_lr: 4.6500000000000005e-05 \n",
            "     | > step_time: 1.5158  (1.5270050764083862)\n",
            "     | > loader_time: 0.02  (0.018991291522979736)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6545751094818115 \u001b[0m(+0.0068950653076171875)\n",
            "     | > avg_loss:\u001b[92m 0.28754279017448425 \u001b[0m(-0.0216311514377594)\n",
            "     | > avg_log_mle:\u001b[92m -0.07660597562789917 \u001b[0m(-0.0017681121826171875)\n",
            "     | > avg_loss_dur:\u001b[92m 0.3641487658023834 \u001b[0m(-0.019863039255142212)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2057.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 187/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:49:14) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6445538997650146 \u001b[0m(-0.010021209716796875)\n",
            "     | > avg_loss:\u001b[91m 0.29165300726890564 \u001b[0m(+0.004110217094421387)\n",
            "     | > avg_log_mle:\u001b[92m -0.0783575177192688 \u001b[0m(-0.001751542091369629)\n",
            "     | > avg_loss_dur:\u001b[91m 0.37001052498817444 \u001b[0m(+0.005861759185791016)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 188/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:49:53) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:50:10 -- STEP: 7/11 -- GLOBAL_STEP: 2075\u001b[0m\n",
            "     | > loss: 0.3005126714706421  (0.27913661514009747)\n",
            "     | > log_mle: -0.11020267009735107  (-0.10839901651654925)\n",
            "     | > loss_dur: 0.41071534156799316  (0.38753563165664673)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(3.6764, device='cuda:0')  (tensor(2.6360, device='cuda:0'))\n",
            "     | > current_lr: 4.7000000000000004e-05 \n",
            "     | > step_time: 0.6652  (1.5776862076350622)\n",
            "     | > loader_time: 0.0067  (0.025177172252110074)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6597115993499756 \u001b[0m(+0.015157699584960938)\n",
            "     | > avg_loss:\u001b[92m 0.28672030568122864 \u001b[0m(-0.004932701587677002)\n",
            "     | > avg_log_mle:\u001b[92m -0.07908034324645996 \u001b[0m(-0.0007228255271911621)\n",
            "     | > avg_loss_dur:\u001b[92m 0.3658006489276886 \u001b[0m(-0.00420987606048584)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2079.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 189/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:50:31) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.0558803081512451 \u001b[0m(+0.39616870880126953)\n",
            "     | > avg_loss:\u001b[92m 0.2770879864692688 \u001b[0m(-0.009632319211959839)\n",
            "     | > avg_log_mle:\u001b[92m -0.08072584867477417 \u001b[0m(-0.001645505428314209)\n",
            "     | > avg_loss_dur:\u001b[92m 0.35781383514404297 \u001b[0m(-0.00798681378364563)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2090.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 190/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:51:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:51:34 -- STEP: 10/11 -- GLOBAL_STEP: 2100\u001b[0m\n",
            "     | > loss: 0.2618868052959442  (0.27468372583389283)\n",
            "     | > log_mle: -0.12922978401184082  (-0.1128659963607788)\n",
            "     | > loss_dur: 0.39111658930778503  (0.38754972219467165)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(1.8349, device='cuda:0')  (tensor(2.5694, device='cuda:0'))\n",
            "     | > current_lr: 4.75e-05 \n",
            "     | > step_time: 0.4311  (1.5633220672607422)\n",
            "     | > loader_time: 0.0048  (0.01679413318634033)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6956868171691895 \u001b[0m(-0.36019349098205566)\n",
            "     | > avg_loss:\u001b[92m 0.270541787147522 \u001b[0m(-0.006546199321746826)\n",
            "     | > avg_log_mle:\u001b[92m -0.08287668228149414 \u001b[0m(-0.0021508336067199707)\n",
            "     | > avg_loss_dur:\u001b[92m 0.3534184694290161 \u001b[0m(-0.0043953657150268555)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2101.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 191/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:51:56) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7346615791320801 \u001b[0m(+0.038974761962890625)\n",
            "     | > avg_loss:\u001b[91m 0.28381800651550293 \u001b[0m(+0.013276219367980957)\n",
            "     | > avg_log_mle:\u001b[91m -0.08174216747283936 \u001b[0m(+0.0011345148086547852)\n",
            "     | > avg_loss_dur:\u001b[91m 0.3655601739883423 \u001b[0m(+0.012141704559326172)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 192/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:52:38) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.71907639503479 \u001b[0m(-0.015585184097290039)\n",
            "     | > avg_loss:\u001b[92m 0.27770793437957764 \u001b[0m(-0.006110072135925293)\n",
            "     | > avg_log_mle:\u001b[92m -0.08406567573547363 \u001b[0m(-0.0023235082626342773)\n",
            "     | > avg_loss_dur:\u001b[92m 0.36177361011505127 \u001b[0m(-0.0037865638732910156)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 193/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:53:14) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:53:28 -- STEP: 2/11 -- GLOBAL_STEP: 2125\u001b[0m\n",
            "     | > loss: 0.25010108947753906  (0.23655802011489868)\n",
            "     | > log_mle: -0.12246859073638916  (-0.11938941478729248)\n",
            "     | > loss_dur: 0.3725696802139282  (0.35594743490219116)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(2.1811, device='cuda:0')  (tensor(2.9006, device='cuda:0'))\n",
            "     | > current_lr: 4.825e-05 \n",
            "     | > step_time: 3.1801  (3.0516997575759888)\n",
            "     | > loader_time: 0.0279  (0.03308212757110596)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6578004360198975 \u001b[0m(-0.06127595901489258)\n",
            "     | > avg_loss:\u001b[92m 0.2730347812175751 \u001b[0m(-0.0046731531620025635)\n",
            "     | > avg_log_mle:\u001b[92m -0.08553361892700195 \u001b[0m(-0.0014679431915283203)\n",
            "     | > avg_loss_dur:\u001b[92m 0.358568400144577 \u001b[0m(-0.003205209970474243)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 194/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:53:51) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6797089576721191 \u001b[0m(+0.02190852165222168)\n",
            "     | > avg_loss:\u001b[92m 0.251668244600296 \u001b[0m(-0.021366536617279053)\n",
            "     | > avg_log_mle:\u001b[92m -0.08804154396057129 \u001b[0m(-0.002507925033569336)\n",
            "     | > avg_loss_dur:\u001b[92m 0.3397097885608673 \u001b[0m(-0.018858611583709717)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2145.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 195/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:54:34) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:54:46 -- STEP: 5/11 -- GLOBAL_STEP: 2150\u001b[0m\n",
            "     | > loss: 0.26296308636665344  (0.2437082588672638)\n",
            "     | > log_mle: -0.11378884315490723  (-0.11854052543640137)\n",
            "     | > loss_dur: 0.37675192952156067  (0.36224878430366514)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(3.2396, device='cuda:0')  (tensor(2.9966, device='cuda:0'))\n",
            "     | > current_lr: 4.875e-05 \n",
            "     | > step_time: 1.0446  (1.4644357681274414)\n",
            "     | > loader_time: 0.0301  (0.024962854385375977)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7059743404388428 \u001b[0m(+0.026265382766723633)\n",
            "     | > avg_loss:\u001b[92m 0.24904945492744446 \u001b[0m(-0.0026187896728515625)\n",
            "     | > avg_log_mle:\u001b[92m -0.08827924728393555 \u001b[0m(-0.0002377033233642578)\n",
            "     | > avg_loss_dur:\u001b[92m 0.33732870221138 \u001b[0m(-0.0023810863494873047)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2156.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 196/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:55:10) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6388933658599854 \u001b[0m(-0.06708097457885742)\n",
            "     | > avg_loss:\u001b[92m 0.2449268102645874 \u001b[0m(-0.004122644662857056)\n",
            "     | > avg_log_mle:\u001b[92m -0.08860468864440918 \u001b[0m(-0.0003254413604736328)\n",
            "     | > avg_loss_dur:\u001b[92m 0.3335314989089966 \u001b[0m(-0.003797203302383423)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2167.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 197/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:55:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:56:13 -- STEP: 8/11 -- GLOBAL_STEP: 2175\u001b[0m\n",
            "     | > loss: 0.2716784179210663  (0.24556073546409607)\n",
            "     | > log_mle: -0.12492108345031738  (-0.12031945586204529)\n",
            "     | > loss_dur: 0.39659950137138367  (0.36588019132614136)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(5.2895, device='cuda:0')  (tensor(4.1795, device='cuda:0'))\n",
            "     | > current_lr: 4.925e-05 \n",
            "     | > step_time: 0.7473  (1.7718259990215302)\n",
            "     | > loader_time: 0.0119  (0.022571325302124023)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6606724262237549 \u001b[0m(+0.02177906036376953)\n",
            "     | > avg_loss:\u001b[91m 0.254291832447052 \u001b[0m(+0.0093650221824646)\n",
            "     | > avg_log_mle:\u001b[92m -0.09083700180053711 \u001b[0m(-0.0022323131561279297)\n",
            "     | > avg_loss_dur:\u001b[91m 0.3451288342475891 \u001b[0m(+0.01159733533859253)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 198/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:56:32) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7172262668609619 \u001b[0m(+0.05655384063720703)\n",
            "     | > avg_loss:\u001b[92m 0.24262312054634094 \u001b[0m(-0.01166871190071106)\n",
            "     | > avg_log_mle:\u001b[92m -0.09267950057983398 \u001b[0m(-0.001842498779296875)\n",
            "     | > avg_loss_dur:\u001b[92m 0.3353026211261749 \u001b[0m(-0.009826213121414185)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2189.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 199/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:57:13) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.999908447265625 \u001b[0m(+0.2826821804046631)\n",
            "     | > avg_loss:\u001b[92m 0.232092022895813 \u001b[0m(-0.010531097650527954)\n",
            "     | > avg_log_mle:\u001b[92m -0.09461820125579834 \u001b[0m(-0.0019387006759643555)\n",
            "     | > avg_loss_dur:\u001b[92m 0.32671022415161133 \u001b[0m(-0.008592396974563599)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2200.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 200/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:57:56) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:58:02 -- STEP: 0/11 -- GLOBAL_STEP: 2200\u001b[0m\n",
            "     | > loss: 0.1483202874660492  (0.1483202874660492)\n",
            "     | > log_mle: -0.14028334617614746  (-0.14028334617614746)\n",
            "     | > loss_dur: 0.28860363364219666  (0.28860363364219666)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(2.3220, device='cuda:0')  (tensor(2.3220, device='cuda:0'))\n",
            "     | > current_lr: 4.9999999999999996e-05 \n",
            "     | > step_time: 1.7889  (1.7889258861541748)\n",
            "     | > loader_time: 3.2159  (3.215874671936035)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/checkpoint_2200.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.5740971565246582 \u001b[0m(+0.5741887092590332)\n",
            "     | > avg_loss:\u001b[92m 0.22814977169036865 \u001b[0m(-0.003942251205444336)\n",
            "     | > avg_log_mle:\u001b[92m -0.09465241432189941 \u001b[0m(-3.421306610107422e-05)\n",
            "     | > avg_loss_dur:\u001b[92m 0.32280218601226807 \u001b[0m(-0.003908038139343262)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2211.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 201/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:58:45) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6678917407989502 \u001b[0m(-0.906205415725708)\n",
            "     | > avg_loss:\u001b[91m 0.2298307716846466 \u001b[0m(+0.001680999994277954)\n",
            "     | > avg_log_mle:\u001b[92m -0.09690511226654053 \u001b[0m(-0.0022526979446411133)\n",
            "     | > avg_loss_dur:\u001b[91m 0.32673588395118713 \u001b[0m(+0.003933697938919067)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 202/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 19:59:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 19:59:41 -- STEP: 3/11 -- GLOBAL_STEP: 2225\u001b[0m\n",
            "     | > loss: 0.19865092635154724  (0.19835466146469116)\n",
            "     | > log_mle: -0.12412893772125244  (-0.1315400997797648)\n",
            "     | > loss_dur: 0.3227798640727997  (0.329894761244456)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(4.1956, device='cuda:0')  (tensor(2.8921, device='cuda:0'))\n",
            "     | > current_lr: 5.05e-05 \n",
            "     | > step_time: 3.8046  (3.072833855946859)\n",
            "     | > loader_time: 0.0561  (0.04345560073852539)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7338457107543945 \u001b[0m(+0.06595396995544434)\n",
            "     | > avg_loss:\u001b[92m 0.22067978978157043 \u001b[0m(-0.009150981903076172)\n",
            "     | > avg_log_mle:\u001b[92m -0.09728634357452393 \u001b[0m(-0.00038123130798339844)\n",
            "     | > avg_loss_dur:\u001b[92m 0.31796613335609436 \u001b[0m(-0.008769750595092773)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2233.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 203/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:00:08) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 2.7136428356170654 \u001b[0m(+1.979797124862671)\n",
            "     | > avg_loss:\u001b[91m 0.22612589597702026 \u001b[0m(+0.005446106195449829)\n",
            "     | > avg_log_mle:\u001b[91m -0.09624111652374268 \u001b[0m(+0.00104522705078125)\n",
            "     | > avg_loss_dur:\u001b[91m 0.32236701250076294 \u001b[0m(+0.004400879144668579)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 204/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:00:54) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 20:01:12 -- STEP: 6/11 -- GLOBAL_STEP: 2250\u001b[0m\n",
            "     | > loss: 0.2193041443824768  (0.20990288257598877)\n",
            "     | > log_mle: -0.12756729125976562  (-0.13058451811472574)\n",
            "     | > loss_dur: 0.34687143564224243  (0.34048740069071454)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(3.6068, device='cuda:0')  (tensor(3.5157, device='cuda:0'))\n",
            "     | > current_lr: 5.1e-05 \n",
            "     | > step_time: 0.7235  (1.9971209367116292)\n",
            "     | > loader_time: 0.0075  (0.030996243158976238)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.687199592590332 \u001b[0m(-2.0264432430267334)\n",
            "     | > avg_loss:\u001b[92m 0.22597825527191162 \u001b[0m(-0.00014764070510864258)\n",
            "     | > avg_log_mle:\u001b[92m -0.10035121440887451 \u001b[0m(-0.004110097885131836)\n",
            "     | > avg_loss_dur:\u001b[91m 0.32632946968078613 \u001b[0m(+0.003962457180023193)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 205/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:01:30) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6882784366607666 \u001b[0m(+0.0010788440704345703)\n",
            "     | > avg_loss:\u001b[92m 0.21715328097343445 \u001b[0m(-0.008824974298477173)\n",
            "     | > avg_log_mle:\u001b[92m -0.10090839862823486 \u001b[0m(-0.0005571842193603516)\n",
            "     | > avg_loss_dur:\u001b[92m 0.3180616796016693 \u001b[0m(-0.008267790079116821)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2266.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 206/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:02:09) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 20:02:33 -- STEP: 9/11 -- GLOBAL_STEP: 2275\u001b[0m\n",
            "     | > loss: 0.22254040837287903  (0.21402962671385872)\n",
            "     | > log_mle: -0.12817144393920898  (-0.1325477891498142)\n",
            "     | > loss_dur: 0.350711852312088  (0.3465774158636729)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(5.9437, device='cuda:0')  (tensor(5.2234, device='cuda:0'))\n",
            "     | > current_lr: 5.15e-05 \n",
            "     | > step_time: 0.916  (2.040280342102051)\n",
            "     | > loader_time: 0.0126  (0.030983236100938585)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6698963642120361 \u001b[0m(-0.01838207244873047)\n",
            "     | > avg_loss:\u001b[92m 0.21710887551307678 \u001b[0m(-4.4405460357666016e-05)\n",
            "     | > avg_log_mle:\u001b[92m -0.10280716419219971 \u001b[0m(-0.0018987655639648438)\n",
            "     | > avg_loss_dur:\u001b[91m 0.3199160397052765 \u001b[0m(+0.0018543601036071777)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2277.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 207/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:02:53) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.9547853469848633 \u001b[0m(+0.28488898277282715)\n",
            "     | > avg_loss:\u001b[92m 0.2075170874595642 \u001b[0m(-0.009591788053512573)\n",
            "     | > avg_log_mle:\u001b[92m -0.10439896583557129 \u001b[0m(-0.001591801643371582)\n",
            "     | > avg_loss_dur:\u001b[92m 0.3119160532951355 \u001b[0m(-0.007999986410140991)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2288.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 208/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:03:40) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6552393436431885 \u001b[0m(-0.2995460033416748)\n",
            "     | > avg_loss:\u001b[92m 0.19944670796394348 \u001b[0m(-0.008070379495620728)\n",
            "     | > avg_log_mle:\u001b[91m -0.10358202457427979 \u001b[0m(+0.0008169412612915039)\n",
            "     | > avg_loss_dur:\u001b[92m 0.30302873253822327 \u001b[0m(-0.008887320756912231)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2299.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 209/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:04:22) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 20:04:34 -- STEP: 1/11 -- GLOBAL_STEP: 2300\u001b[0m\n",
            "     | > loss: 0.1602274775505066  (0.1602274775505066)\n",
            "     | > log_mle: -0.14330768585205078  (-0.14330768585205078)\n",
            "     | > loss_dur: 0.3035351634025574  (0.3035351634025574)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(1.9115, device='cuda:0')  (tensor(1.9115, device='cuda:0'))\n",
            "     | > current_lr: 5.225e-05 \n",
            "     | > step_time: 3.0949  (3.094902992248535)\n",
            "     | > loader_time: 0.047  (0.04700326919555664)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.2031259536743164 \u001b[0m(+0.5478866100311279)\n",
            "     | > avg_loss:\u001b[92m 0.1936817765235901 \u001b[0m(-0.0057649314403533936)\n",
            "     | > avg_log_mle:\u001b[92m -0.10559642314910889 \u001b[0m(-0.0020143985748291016)\n",
            "     | > avg_loss_dur:\u001b[92m 0.299278199672699 \u001b[0m(-0.003750532865524292)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2310.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 210/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:05:11) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6694684028625488 \u001b[0m(-0.5336575508117676)\n",
            "     | > avg_loss:\u001b[91m 0.19440093636512756 \u001b[0m(+0.0007191598415374756)\n",
            "     | > avg_log_mle:\u001b[92m -0.10700571537017822 \u001b[0m(-0.001409292221069336)\n",
            "     | > avg_loss_dur:\u001b[91m 0.3014066517353058 \u001b[0m(+0.0021284520626068115)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 211/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:05:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 20:06:08 -- STEP: 4/11 -- GLOBAL_STEP: 2325\u001b[0m\n",
            "     | > loss: 0.19221782684326172  (0.1732589229941368)\n",
            "     | > log_mle: -0.13830387592315674  (-0.14202389121055603)\n",
            "     | > loss_dur: 0.33052170276641846  (0.31528281420469284)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(2.3889, device='cuda:0')  (tensor(2.9825, device='cuda:0'))\n",
            "     | > current_lr: 5.275e-05 \n",
            "     | > step_time: 1.1623  (2.424861192703247)\n",
            "     | > loader_time: 0.0224  (0.040836870670318604)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.699561357498169 \u001b[0m(+0.030092954635620117)\n",
            "     | > avg_loss:\u001b[92m 0.19063344597816467 \u001b[0m(-0.0037674903869628906)\n",
            "     | > avg_log_mle:\u001b[92m -0.10919404029846191 \u001b[0m(-0.0021883249282836914)\n",
            "     | > avg_loss_dur:\u001b[92m 0.2998274862766266 \u001b[0m(-0.0015791654586791992)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2332.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 212/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:06:31) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.9943051338195801 \u001b[0m(+0.29474377632141113)\n",
            "     | > avg_loss:\u001b[92m 0.1875099241733551 \u001b[0m(-0.0031235218048095703)\n",
            "     | > avg_log_mle:\u001b[92m -0.11152708530426025 \u001b[0m(-0.00233304500579834)\n",
            "     | > avg_loss_dur:\u001b[92m 0.29903700947761536 \u001b[0m(-0.0007904767990112305)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2343.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 213/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:07:17) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 20:07:38 -- STEP: 7/11 -- GLOBAL_STEP: 2350\u001b[0m\n",
            "     | > loss: 0.20956218242645264  (0.1816375723906926)\n",
            "     | > log_mle: -0.14311444759368896  (-0.14231790815080916)\n",
            "     | > loss_dur: 0.3526766300201416  (0.32395548054150175)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(2.6706, device='cuda:0')  (tensor(3.5653, device='cuda:0'))\n",
            "     | > current_lr: 5.325e-05 \n",
            "     | > step_time: 0.7142  (2.2385196685791016)\n",
            "     | > loader_time: 0.0062  (0.019446815763201033)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.57566499710083 \u001b[0m(+0.58135986328125)\n",
            "     | > avg_loss:\u001b[92m 0.17113643884658813 \u001b[0m(-0.016373485326766968)\n",
            "     | > avg_log_mle:\u001b[91m -0.11122786998748779 \u001b[0m(+0.00029921531677246094)\n",
            "     | > avg_loss_dur:\u001b[92m 0.2823643088340759 \u001b[0m(-0.01667270064353943)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000/best_model_2354.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 214/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:08:04) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7235536575317383 \u001b[0m(-0.8521113395690918)\n",
            "     | > avg_loss:\u001b[91m 0.1895299255847931 \u001b[0m(+0.018393486738204956)\n",
            "     | > avg_log_mle:\u001b[92m -0.11278283596038818 \u001b[0m(-0.0015549659729003906)\n",
            "     | > avg_loss_dur:\u001b[91m 0.3023127615451813 \u001b[0m(+0.019948452711105347)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 215/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:08:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-06-19 20:09:03 -- STEP: 10/11 -- GLOBAL_STEP: 2375\u001b[0m\n",
            "     | > loss: 0.1673840582370758  (0.1810850590467453)\n",
            "     | > log_mle: -0.16402220726013184  (-0.1470654010772705)\n",
            "     | > loss_dur: 0.33140626549720764  (0.32815046012401583)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > grad_norm: tensor(1.8118, device='cuda:0')  (tensor(2.8061, device='cuda:0'))\n",
            "     | > current_lr: 5.375e-05 \n",
            "     | > step_time: 0.416  (1.4584625959396362)\n",
            "     | > loader_time: 0.0055  (0.025617575645446776)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.713526725769043 \u001b[0m(-0.010026931762695312)\n",
            "     | > avg_loss:\u001b[92m 0.18460598587989807 \u001b[0m(-0.0049239397048950195)\n",
            "     | > avg_log_mle:\u001b[92m -0.1147911548614502 \u001b[0m(-0.0020083189010620117)\n",
            "     | > avg_loss_dur:\u001b[92m 0.29939714074134827 \u001b[0m(-0.002915620803833008)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 216/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:09:20) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6896748542785645 \u001b[0m(-0.023851871490478516)\n",
            "     | > avg_loss:\u001b[91m 0.18584445118904114 \u001b[0m(+0.0012384653091430664)\n",
            "     | > avg_log_mle:\u001b[91m -0.11471962928771973 \u001b[0m(+7.152557373046875e-05)\n",
            "     | > avg_loss_dur:\u001b[91m 0.30056408047676086 \u001b[0m(+0.0011669397354125977)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 217/250\u001b[0m\n",
            " --> /content/drive/MyDrive/ljspeech-002/tts_train_dir/run-June-19-2024_05+47PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-06-19 20:09:56) \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# start the training process\n",
        "trainer.fit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5228410,
          "sourceId": 8715008,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30732,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
